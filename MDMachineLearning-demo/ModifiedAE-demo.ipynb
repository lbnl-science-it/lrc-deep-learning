{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "seed(2020) #set random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the processed data, note that we've already converted the dcd/pdb file to csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca=pd.read_csv('./Ala13/PCAanalysis.csv',names=['PCA1','PCA2'])\n",
    "df_cor=pd.read_csv('./Ala13/Atoms_coordinates_whole.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PCA1</th>\n",
       "      <th>PCA2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.002330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.000557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0168</td>\n",
       "      <td>-0.000337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0175</td>\n",
       "      <td>-0.001910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0177</td>\n",
       "      <td>-0.001320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PCA1      PCA2\n",
       "0  0.0162  0.002330\n",
       "1  0.0164  0.000557\n",
       "2  0.0168 -0.000337\n",
       "3  0.0175 -0.001910\n",
       "4  0.0177 -0.001320"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.130003</td>\n",
       "      <td>30.730001</td>\n",
       "      <td>33.320004</td>\n",
       "      <td>28.780001</td>\n",
       "      <td>30.370003</td>\n",
       "      <td>32.850002</td>\n",
       "      <td>27.740002</td>\n",
       "      <td>31.210001</td>\n",
       "      <td>33.570000</td>\n",
       "      <td>28.580000</td>\n",
       "      <td>...</td>\n",
       "      <td>18.540001</td>\n",
       "      <td>20.970001</td>\n",
       "      <td>20.630001</td>\n",
       "      <td>18.210001</td>\n",
       "      <td>21.800001</td>\n",
       "      <td>19.700001</td>\n",
       "      <td>18.200001</td>\n",
       "      <td>19.960001</td>\n",
       "      <td>20.500002</td>\n",
       "      <td>17.490002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.582726</td>\n",
       "      <td>31.034544</td>\n",
       "      <td>33.609142</td>\n",
       "      <td>29.322193</td>\n",
       "      <td>30.378710</td>\n",
       "      <td>33.246048</td>\n",
       "      <td>28.169268</td>\n",
       "      <td>31.027327</td>\n",
       "      <td>34.018612</td>\n",
       "      <td>29.069057</td>\n",
       "      <td>...</td>\n",
       "      <td>18.046659</td>\n",
       "      <td>21.080175</td>\n",
       "      <td>19.482227</td>\n",
       "      <td>17.698109</td>\n",
       "      <td>21.676388</td>\n",
       "      <td>18.441927</td>\n",
       "      <td>18.062536</td>\n",
       "      <td>20.435606</td>\n",
       "      <td>19.408522</td>\n",
       "      <td>16.636789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.547211</td>\n",
       "      <td>30.999948</td>\n",
       "      <td>33.498272</td>\n",
       "      <td>28.881954</td>\n",
       "      <td>30.967804</td>\n",
       "      <td>32.882378</td>\n",
       "      <td>29.850468</td>\n",
       "      <td>30.103348</td>\n",
       "      <td>33.687733</td>\n",
       "      <td>28.909615</td>\n",
       "      <td>...</td>\n",
       "      <td>17.698475</td>\n",
       "      <td>21.072111</td>\n",
       "      <td>20.966135</td>\n",
       "      <td>17.106026</td>\n",
       "      <td>21.194897</td>\n",
       "      <td>19.720905</td>\n",
       "      <td>17.171005</td>\n",
       "      <td>20.400530</td>\n",
       "      <td>21.533232</td>\n",
       "      <td>16.229221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.889790</td>\n",
       "      <td>30.885441</td>\n",
       "      <td>33.714222</td>\n",
       "      <td>29.036554</td>\n",
       "      <td>30.401567</td>\n",
       "      <td>32.932556</td>\n",
       "      <td>29.474493</td>\n",
       "      <td>29.073942</td>\n",
       "      <td>33.540764</td>\n",
       "      <td>28.938217</td>\n",
       "      <td>...</td>\n",
       "      <td>18.102945</td>\n",
       "      <td>22.408243</td>\n",
       "      <td>19.916569</td>\n",
       "      <td>17.357298</td>\n",
       "      <td>23.642900</td>\n",
       "      <td>19.738064</td>\n",
       "      <td>17.475031</td>\n",
       "      <td>21.699007</td>\n",
       "      <td>19.404203</td>\n",
       "      <td>16.474821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27.751440</td>\n",
       "      <td>29.981630</td>\n",
       "      <td>33.914619</td>\n",
       "      <td>28.425182</td>\n",
       "      <td>30.937717</td>\n",
       "      <td>33.022114</td>\n",
       "      <td>29.750643</td>\n",
       "      <td>31.394354</td>\n",
       "      <td>33.635334</td>\n",
       "      <td>28.520418</td>\n",
       "      <td>...</td>\n",
       "      <td>18.586025</td>\n",
       "      <td>21.225840</td>\n",
       "      <td>20.214525</td>\n",
       "      <td>17.992739</td>\n",
       "      <td>22.343639</td>\n",
       "      <td>20.065355</td>\n",
       "      <td>17.446964</td>\n",
       "      <td>20.361906</td>\n",
       "      <td>19.368549</td>\n",
       "      <td>17.718796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0  30.130003  30.730001  33.320004  28.780001  30.370003  32.850002   \n",
       "1  30.582726  31.034544  33.609142  29.322193  30.378710  33.246048   \n",
       "2  27.547211  30.999948  33.498272  28.881954  30.967804  32.882378   \n",
       "3  27.889790  30.885441  33.714222  29.036554  30.401567  32.932556   \n",
       "4  27.751440  29.981630  33.914619  28.425182  30.937717  33.022114   \n",
       "\n",
       "         6          7          8          9    ...        188        189  \\\n",
       "0  27.740002  31.210001  33.570000  28.580000  ...  18.540001  20.970001   \n",
       "1  28.169268  31.027327  34.018612  29.069057  ...  18.046659  21.080175   \n",
       "2  29.850468  30.103348  33.687733  28.909615  ...  17.698475  21.072111   \n",
       "3  29.474493  29.073942  33.540764  28.938217  ...  18.102945  22.408243   \n",
       "4  29.750643  31.394354  33.635334  28.520418  ...  18.586025  21.225840   \n",
       "\n",
       "         190        191        192        193        194        195  \\\n",
       "0  20.630001  18.210001  21.800001  19.700001  18.200001  19.960001   \n",
       "1  19.482227  17.698109  21.676388  18.441927  18.062536  20.435606   \n",
       "2  20.966135  17.106026  21.194897  19.720905  17.171005  20.400530   \n",
       "3  19.916569  17.357298  23.642900  19.738064  17.475031  21.699007   \n",
       "4  20.214525  17.992739  22.343639  20.065355  17.446964  20.361906   \n",
       "\n",
       "         196        197  \n",
       "0  20.500002  17.490002  \n",
       "1  19.408522  16.636789  \n",
       "2  21.533232  16.229221  \n",
       "3  19.404203  16.474821  \n",
       "4  19.368549  17.718796  \n",
       "\n",
       "[5 rows x 198 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate the PCA values and its corresponding trajectories,here we regard PC1/PC2 values as labels in machine learning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.62000000e-02, 2.33000000e-03, 3.01300030e+01, 3.07300014e+01,\n",
       "        3.33200035e+01, 2.87800007e+01, 3.03700028e+01, 3.28500023e+01,\n",
       "        2.77400017e+01, 3.12100010e+01, 3.35699997e+01, 2.85799999e+01,\n",
       "        3.03899994e+01, 3.13400002e+01, 2.79200001e+01, 2.94400024e+01,\n",
       "        3.09200020e+01, 2.90000000e+01, 3.14500027e+01, 3.06500015e+01,\n",
       "        2.90800018e+01, 3.16399994e+01, 2.92200012e+01, 3.00400009e+01,\n",
       "        3.27800026e+01, 2.88800030e+01, 2.94800014e+01, 3.03199997e+01,\n",
       "        2.85600014e+01, 2.88500023e+01, 2.98400021e+01, 2.76200008e+01,\n",
       "        3.04900017e+01, 2.96400032e+01, 2.91000004e+01, 3.10700016e+01,\n",
       "        2.84600029e+01, 2.84799995e+01, 3.25200005e+01, 2.82200012e+01,\n",
       "        2.89000015e+01, 3.02100010e+01, 2.72100029e+01, 2.86100006e+01,\n",
       "        2.99600010e+01, 2.65200024e+01, 2.76300030e+01, 2.97900009e+01,\n",
       "        2.69100017e+01, 2.98400021e+01, 2.89300003e+01, 2.58100014e+01,\n",
       "        3.02300034e+01, 2.88900013e+01, 2.57200012e+01, 3.17500019e+01,\n",
       "        2.75700016e+01, 2.59799995e+01, 2.95700035e+01, 2.70600014e+01,\n",
       "        2.49800014e+01, 2.90699997e+01, 2.69800014e+01, 2.71700020e+01,\n",
       "        2.94400024e+01, 2.57700005e+01, 2.74600010e+01, 2.86900024e+01,\n",
       "        2.52600002e+01, 2.88500023e+01, 2.90200024e+01, 2.59200001e+01,\n",
       "        2.72600002e+01, 2.71800022e+01, 2.50400009e+01, 2.66200028e+01,\n",
       "        2.66200028e+01, 2.70900002e+01, 2.76100006e+01, 2.66300011e+01,\n",
       "        2.74000015e+01, 2.72299995e+01, 2.52700024e+01, 2.85499992e+01,\n",
       "        2.81000023e+01, 2.47800026e+01, 2.75400009e+01, 2.57400017e+01,\n",
       "        2.49900017e+01, 2.70500011e+01, 2.53000031e+01, 2.39500027e+01,\n",
       "        2.81700020e+01, 2.50100021e+01, 2.59200001e+01, 2.82000008e+01,\n",
       "        2.35600014e+01, 2.59099998e+01, 2.90000000e+01, 2.30000019e+01,\n",
       "        2.70800018e+01, 2.68100014e+01, 2.29400024e+01, 2.58700008e+01,\n",
       "        2.65400009e+01, 2.21300011e+01, 2.49800014e+01, 2.59099998e+01,\n",
       "        2.34000015e+01, 2.67500019e+01, 2.45600014e+01, 2.28800011e+01,\n",
       "        2.67800026e+01, 2.39099998e+01, 2.33700008e+01, 2.80700016e+01,\n",
       "        2.37200012e+01, 2.32600021e+01, 2.55600014e+01, 2.28700028e+01,\n",
       "        2.25200005e+01, 2.50800018e+01, 2.40300007e+01, 2.44400005e+01,\n",
       "        2.50200005e+01, 2.34000015e+01, 2.49300003e+01, 2.38100014e+01,\n",
       "        2.37800007e+01, 2.63900013e+01, 2.35300026e+01, 2.36900024e+01,\n",
       "        2.41200028e+01, 2.25600014e+01, 2.28199997e+01, 2.37700005e+01,\n",
       "        2.17600021e+01, 2.49800014e+01, 2.37700005e+01, 2.24100017e+01,\n",
       "        2.54700012e+01, 2.29400024e+01, 2.13300018e+01, 2.69500008e+01,\n",
       "        2.32700005e+01, 2.11600017e+01, 2.51500015e+01, 2.14600010e+01,\n",
       "        2.15000000e+01, 2.53899994e+01, 2.07100010e+01, 2.05700016e+01,\n",
       "        2.47400017e+01, 2.10799999e+01, 2.27100010e+01, 2.42300014e+01,\n",
       "        1.97500019e+01, 2.30000019e+01, 2.45100021e+01, 1.94300003e+01,\n",
       "        2.44700012e+01, 2.27500000e+01, 1.97200012e+01, 2.26500015e+01,\n",
       "        2.22299995e+01, 1.87100010e+01, 2.21700001e+01, 2.19600010e+01,\n",
       "        2.07600021e+01, 2.29400024e+01, 2.05599995e+01, 2.09000015e+01,\n",
       "        2.25900002e+01, 1.99200020e+01, 2.19600010e+01, 2.34799995e+01,\n",
       "        2.03100014e+01, 2.12600021e+01, 2.11300011e+01, 1.91900024e+01,\n",
       "        2.10400009e+01, 2.06800003e+01, 2.12700005e+01, 2.18600006e+01,\n",
       "        2.04200001e+01, 2.12800007e+01, 2.19100017e+01, 1.89700012e+01,\n",
       "        2.26400013e+01, 2.24600010e+01, 1.85400009e+01, 2.09700012e+01,\n",
       "        2.06300011e+01, 1.82100010e+01, 2.18000011e+01, 1.97000008e+01,\n",
       "        1.82000008e+01, 1.99600010e+01, 2.05000019e+01, 1.74900017e+01],\n",
       "       [1.64000000e-02, 5.57000000e-04, 3.05827255e+01, 3.10345440e+01,\n",
       "        3.36091423e+01, 2.93221932e+01, 3.03787098e+01, 3.32460480e+01,\n",
       "        2.81692676e+01, 3.10273266e+01, 3.40186119e+01, 2.90690575e+01,\n",
       "        3.03275661e+01, 3.17423820e+01, 2.84527416e+01, 2.93733921e+01,\n",
       "        3.12636261e+01, 2.95374031e+01, 3.13431072e+01, 3.10147667e+01,\n",
       "        2.92576084e+01, 3.14215679e+01, 2.95929127e+01, 2.97234745e+01,\n",
       "        3.27747650e+01, 2.90629883e+01, 2.97507858e+01, 3.02569428e+01,\n",
       "        2.87505169e+01, 2.90006523e+01, 2.99801941e+01, 2.78212147e+01,\n",
       "        3.08601665e+01, 2.95998669e+01, 2.91163406e+01, 3.13642921e+01,\n",
       "        2.84202919e+01, 2.84271011e+01, 3.28558578e+01, 2.83496342e+01,\n",
       "        2.87536640e+01, 3.06288319e+01, 2.71476231e+01, 2.88039532e+01,\n",
       "        3.06419582e+01, 2.62702351e+01, 2.79429550e+01, 2.98624764e+01,\n",
       "        2.71399307e+01, 2.98889599e+01, 2.89360676e+01, 2.61052418e+01,\n",
       "        3.03314285e+01, 2.87045326e+01, 2.61204052e+01, 3.18368397e+01,\n",
       "        2.76078358e+01, 2.61679611e+01, 2.95915146e+01, 2.71973705e+01,\n",
       "        2.52176971e+01, 2.89462910e+01, 2.69424801e+01, 2.73285370e+01,\n",
       "        2.95787277e+01, 2.57604942e+01, 2.76631241e+01, 2.88163853e+01,\n",
       "        2.54733696e+01, 2.91532822e+01, 2.90183411e+01, 2.58570843e+01,\n",
       "        2.74176426e+01, 2.73177147e+01, 2.49239464e+01, 2.68425560e+01,\n",
       "        2.67732601e+01, 2.69601288e+01, 2.78256130e+01, 2.66812782e+01,\n",
       "        2.71186657e+01, 2.75803986e+01, 2.52598247e+01, 2.83253365e+01,\n",
       "        2.83481808e+01, 2.47203293e+01, 2.72440605e+01, 2.60867958e+01,\n",
       "        2.49959660e+01, 2.64953384e+01, 2.56600132e+01, 2.41165504e+01,\n",
       "        2.79815712e+01, 2.52983017e+01, 2.57849255e+01, 2.80749836e+01,\n",
       "        2.38552208e+01, 2.57019653e+01, 2.89921131e+01, 2.34636650e+01,\n",
       "        2.68557243e+01, 2.67119179e+01, 2.31756763e+01, 2.57695961e+01,\n",
       "        2.65177689e+01, 2.22614307e+01, 2.49740086e+01, 2.57177200e+01,\n",
       "        2.36635246e+01, 2.65111980e+01, 2.44087543e+01, 2.30510216e+01,\n",
       "        2.65403767e+01, 2.37881756e+01, 2.31817989e+01, 2.79314442e+01,\n",
       "        2.34396172e+01, 2.34874611e+01, 2.54489098e+01, 2.24287643e+01,\n",
       "        2.28097420e+01, 2.52715073e+01, 2.37180424e+01, 2.45256233e+01,\n",
       "        2.46443596e+01, 2.30810165e+01, 2.49027882e+01, 2.33993130e+01,\n",
       "        2.31943665e+01, 2.64083748e+01, 2.32294006e+01, 2.36362419e+01,\n",
       "        2.39831753e+01, 2.23198032e+01, 2.28665466e+01, 2.34644375e+01,\n",
       "        2.15132217e+01, 2.49306049e+01, 2.36657715e+01, 2.23288364e+01,\n",
       "        2.56055908e+01, 2.27272453e+01, 2.14576549e+01, 2.70928478e+01,\n",
       "        2.27066860e+01, 2.17926826e+01, 2.51001301e+01, 2.13005848e+01,\n",
       "        2.16815834e+01, 2.52498913e+01, 2.05108261e+01, 2.07495117e+01,\n",
       "        2.46492767e+01, 2.09451351e+01, 2.28824520e+01, 2.40094910e+01,\n",
       "        1.96839390e+01, 2.31928616e+01, 2.38062859e+01, 1.95820694e+01,\n",
       "        2.47083263e+01, 2.27033176e+01, 1.94768295e+01, 2.24426498e+01,\n",
       "        2.25565529e+01, 1.85390225e+01, 2.16570435e+01, 2.17390194e+01,\n",
       "        2.03423519e+01, 2.27717361e+01, 2.04466648e+01, 2.03817749e+01,\n",
       "        2.21170864e+01, 1.98026180e+01, 2.16592979e+01, 2.26398086e+01,\n",
       "        2.02943077e+01, 2.02737083e+01, 2.06117611e+01, 1.92697067e+01,\n",
       "        1.97494507e+01, 2.01806641e+01, 2.12834339e+01, 2.07540321e+01,\n",
       "        1.98553753e+01, 2.11853619e+01, 2.08264427e+01, 1.84081936e+01,\n",
       "        2.24104939e+01, 2.16515751e+01, 1.80466595e+01, 2.10801754e+01,\n",
       "        1.94822273e+01, 1.76981087e+01, 2.16763878e+01, 1.84419270e+01,\n",
       "        1.80625362e+01, 2.04356060e+01, 1.94085217e+01, 1.66367893e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data=np.concatenate((df_pca,df_cor),axis=1)\n",
    "train_data.shape, df_pca.shape, df_cor.shape\n",
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(train_data)\n",
    "train_dataset=train_data[:2000]\n",
    "test_dataset=train_data[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_pd=pd.DataFrame(train_dataset)\n",
    "#train_dataset_pd\n",
    "test_dataset_pd=pd.DataFrame(test_dataset)\n",
    "#train_dataset_pd.to_csv('train_data.csv',header=None,index=None)\n",
    "#test_dataset_pd.to_csv('test_data_500.csv',header=None,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2000, 2), (2000, 198), (500, 2), (500, 198))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test=test_dataset[:,:2]\n",
    "Y_test=test_dataset[:,2:]\n",
    "X_train=train_dataset[:,:2]\n",
    "Y_train=train_dataset[:,2:]\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "# note that we must define two minmaxscalers\n",
    "scalar1 = MinMaxScaler()\n",
    "scalar2 = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_train=scalar1.fit_transform(X_train)\n",
    "Y_scaled_train=scalar2.fit_transform(Y_train)\n",
    "X_scaled_test=scalar1.transform(X_test)\n",
    "Y_scaled_test=scalar2.transform(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input,Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras import regularizers\n",
    "from keras.losses import mean_squared_error, binary_crossentropy\n",
    "from keras import objectives\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 2\n",
    "intermediate_dim_1=16\n",
    "intermediate_dim_2=32\n",
    "intermediate_dim_3=64\n",
    "original_dim=198\n",
    "#Encoder part\n",
    "input_net=Input(shape=(original_dim,), name=\"embeding\")\n",
    "encoded_h_3 = Dense(intermediate_dim_3, activation='relu', name=\"hiddenLayer1\",kernel_initializer='normal')(input_net)\n",
    "encoded_h_2 = Dense(intermediate_dim_2, activation='relu', name=\"hiddenLayer2\",kernel_initializer='normal')(encoded_h_3)\n",
    "encoded_h_1 = Dense(intermediate_dim_1, activation='relu', name=\"hiddenLayer3\",kernel_initializer='normal')(encoded_h_2)\n",
    "PCA=Dense(latent_dim, activation='sigmoid', name=\"encode_out\",kernel_initializer='normal')(encoded_h_1)\n",
    "\n",
    "#PCA=Dense(latent_dim, activation='relu', name=\"encode_out\")(input_net)\n",
    "#Decoder part\n",
    "decoded_h_1= Dense(intermediate_dim_1,kernel_initializer='normal', activation='relu', name=\"hiddenLayer4\")(PCA)\n",
    "decoded_h_2= Dense(intermediate_dim_2,kernel_initializer='normal', activation='relu', name=\"hiddenLayer5\")(decoded_h_1)\n",
    "decoded_h_3= Dense(intermediate_dim_3,kernel_initializer='normal', activation='relu', name=\"hiddenLayer6\")(decoded_h_2)\n",
    "decoded = Dense(original_dim,kernel_initializer='normal', activation='sigmoid', name=\"decode_out\")(decoded_h_3)\n",
    "#decoded = Dense(original_dim, activation='sigmoid', name=\"decode_out\")(PCA)\n",
    "# end-to-end autoencoder\n",
    "autoencoder = Model(inputs=input_net, outputs=[PCA, decoded], name=\"AutoEncoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function, we use the mse loss function in two different part in modified AE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latent_loss(y_true, y_pred):\n",
    "    return mean_squared_error(y_true,y_pred)\n",
    "\n",
    "# loss compile\n",
    "adam=optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.99, epsilon=1e-08)\n",
    "autoencoder.compile(optimizer=adam,\n",
    "              loss={'encode_out': latent_loss,'decode_out': latent_loss},\n",
    "              loss_weights={'encode_out':1, 'decode_out': 1},\n",
    "              metrics=[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the structure of autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embeding (InputLayer)        (None, 198)               0         \n",
      "_________________________________________________________________\n",
      "hiddenLayer1 (Dense)         (None, 64)                12736     \n",
      "_________________________________________________________________\n",
      "hiddenLayer2 (Dense)         (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "hiddenLayer3 (Dense)         (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "encode_out (Dense)           (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "hiddenLayer4 (Dense)         (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "hiddenLayer5 (Dense)         (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "hiddenLayer6 (Dense)         (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "decode_out (Dense)           (None, 198)               12870     \n",
      "=================================================================\n",
      "Total params: 30,952\n",
      "Trainable params: 30,952\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"638pt\" viewBox=\"0.00 0.00 144.00 638.00\" width=\"144pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 634)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,5 -4,-634 141,-634 141,5 -4,5\" stroke=\"white\"/>\n",
       "<!-- 47080834837136 -->\n",
       "<g class=\"node\" id=\"node1\"><title>47080834837136</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-593 -0.5,-629 136.5,-629 136.5,-593 -0.5,-593\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-607.3\">embeding: InputLayer</text>\n",
       "</g>\n",
       "<!-- 47080834837192 -->\n",
       "<g class=\"node\" id=\"node2\"><title>47080834837192</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-519 2.5,-555 133.5,-555 133.5,-519 2.5,-519\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-533.3\">hiddenLayer1: Dense</text>\n",
       "</g>\n",
       "<!-- 47080834837136&#45;&gt;47080834837192 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>47080834837136-&gt;47080834837192</title>\n",
       "<path d=\"M68,-592.937C68,-584.807 68,-574.876 68,-565.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"71.5001,-565.441 68,-555.441 64.5001,-565.441 71.5001,-565.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 47080834838088 -->\n",
       "<g class=\"node\" id=\"node3\"><title>47080834838088</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-445 2.5,-481 133.5,-481 133.5,-445 2.5,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-459.3\">hiddenLayer2: Dense</text>\n",
       "</g>\n",
       "<!-- 47080834837192&#45;&gt;47080834838088 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>47080834837192-&gt;47080834838088</title>\n",
       "<path d=\"M68,-518.937C68,-510.807 68,-500.876 68,-491.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"71.5001,-491.441 68,-481.441 64.5001,-491.441 71.5001,-491.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 47080834838256 -->\n",
       "<g class=\"node\" id=\"node4\"><title>47080834838256</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-371 2.5,-407 133.5,-407 133.5,-371 2.5,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-385.3\">hiddenLayer3: Dense</text>\n",
       "</g>\n",
       "<!-- 47080834838088&#45;&gt;47080834838256 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>47080834838088-&gt;47080834838256</title>\n",
       "<path d=\"M68,-444.937C68,-436.807 68,-426.876 68,-417.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"71.5001,-417.441 68,-407.441 64.5001,-417.441 71.5001,-417.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 47080834838368 -->\n",
       "<g class=\"node\" id=\"node5\"><title>47080834838368</title>\n",
       "<polygon fill=\"none\" points=\"8,-297 8,-333 128,-333 128,-297 8,-297\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-311.3\">encode_out: Dense</text>\n",
       "</g>\n",
       "<!-- 47080834838256&#45;&gt;47080834838368 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>47080834838256-&gt;47080834838368</title>\n",
       "<path d=\"M68,-370.937C68,-362.807 68,-352.876 68,-343.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"71.5001,-343.441 68,-333.441 64.5001,-343.441 71.5001,-343.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 47080834807960 -->\n",
       "<g class=\"node\" id=\"node6\"><title>47080834807960</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-223 2.5,-259 133.5,-259 133.5,-223 2.5,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-237.3\">hiddenLayer4: Dense</text>\n",
       "</g>\n",
       "<!-- 47080834838368&#45;&gt;47080834807960 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>47080834838368-&gt;47080834807960</title>\n",
       "<path d=\"M68,-296.937C68,-288.807 68,-278.876 68,-269.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"71.5001,-269.441 68,-259.441 64.5001,-269.441 71.5001,-269.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 47080834951152 -->\n",
       "<g class=\"node\" id=\"node7\"><title>47080834951152</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-149 2.5,-185 133.5,-185 133.5,-149 2.5,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-163.3\">hiddenLayer5: Dense</text>\n",
       "</g>\n",
       "<!-- 47080834807960&#45;&gt;47080834951152 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>47080834807960-&gt;47080834951152</title>\n",
       "<path d=\"M68,-222.937C68,-214.807 68,-204.876 68,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"71.5001,-195.441 68,-185.441 64.5001,-195.441 71.5001,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 47080837302480 -->\n",
       "<g class=\"node\" id=\"node8\"><title>47080837302480</title>\n",
       "<polygon fill=\"none\" points=\"2.5,-75 2.5,-111 133.5,-111 133.5,-75 2.5,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-89.3\">hiddenLayer6: Dense</text>\n",
       "</g>\n",
       "<!-- 47080834951152&#45;&gt;47080837302480 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>47080834951152-&gt;47080837302480</title>\n",
       "<path d=\"M68,-148.937C68,-140.807 68,-130.876 68,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"71.5001,-121.441 68,-111.441 64.5001,-121.441 71.5001,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 47080837442416 -->\n",
       "<g class=\"node\" id=\"node9\"><title>47080837442416</title>\n",
       "<polygon fill=\"none\" points=\"8,-1 8,-37 128,-37 128,-1 8,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"68\" y=\"-15.3\">decode_out: Dense</text>\n",
       "</g>\n",
       "<!-- 47080837302480&#45;&gt;47080837442416 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>47080837302480-&gt;47080837442416</title>\n",
       "<path d=\"M68,-74.937C68,-66.8072 68,-56.8761 68,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"71.5001,-47.4406 68,-37.4407 64.5001,-47.4407 71.5001,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "plot_model(autoencoder, to_file='ModifiedAE.png')\n",
    "SVG(model_to_dot(autoencoder).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2000 samples, validate on 500 samples\n",
      "Epoch 1/100\n",
      "2000/2000 [==============================] - 3s 1ms/step - loss: 0.0511 - encode_out_loss: 0.0274 - decode_out_loss: 0.0237 - encode_out_mean_squared_error: 0.0274 - decode_out_mean_squared_error: 0.0237 - val_loss: 0.0274 - val_encode_out_loss: 0.0053 - val_decode_out_loss: 0.0222 - val_encode_out_mean_squared_error: 0.0053 - val_decode_out_mean_squared_error: 0.0222\n",
      "Epoch 2/100\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.0237 - encode_out_loss: 0.0035 - decode_out_loss: 0.0201 - encode_out_mean_squared_error: 0.0035 - decode_out_mean_squared_error: 0.0201 - val_loss: 0.0226 - val_encode_out_loss: 0.0025 - val_decode_out_loss: 0.0202 - val_encode_out_mean_squared_error: 0.0025 - val_decode_out_mean_squared_error: 0.0202\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.0200 - encode_out_loss: 0.0019 - decode_out_loss: 0.0181 - encode_out_mean_squared_error: 0.0019 - decode_out_mean_squared_error: 0.0181 - val_loss: 0.0192 - val_encode_out_loss: 0.0016 - val_decode_out_loss: 0.0176 - val_encode_out_mean_squared_error: 0.0016 - val_decode_out_mean_squared_error: 0.0176\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.0172 - encode_out_loss: 0.0012 - decode_out_loss: 0.0159 - encode_out_mean_squared_error: 0.0012 - decode_out_mean_squared_error: 0.0159 - val_loss: 0.0166 - val_encode_out_loss: 0.0012 - val_decode_out_loss: 0.0154 - val_encode_out_mean_squared_error: 0.0012 - val_decode_out_mean_squared_error: 0.0154\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0141 - encode_out_loss: 9.8857e-04 - decode_out_loss: 0.0131 - encode_out_mean_squared_error: 9.8857e-04 - decode_out_mean_squared_error: 0.0131 - val_loss: 0.0122 - val_encode_out_loss: 7.4574e-04 - val_decode_out_loss: 0.0114 - val_encode_out_mean_squared_error: 7.4574e-04 - val_decode_out_mean_squared_error: 0.0114\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.0112 - encode_out_loss: 8.3965e-04 - decode_out_loss: 0.0104 - encode_out_mean_squared_error: 8.3965e-04 - decode_out_mean_squared_error: 0.0104 - val_loss: 0.0107 - val_encode_out_loss: 7.2782e-04 - val_decode_out_loss: 0.0099 - val_encode_out_mean_squared_error: 7.2782e-04 - val_decode_out_mean_squared_error: 0.0099\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 0.0102 - encode_out_loss: 6.8730e-04 - decode_out_loss: 0.0095 - encode_out_mean_squared_error: 6.8730e-04 - decode_out_mean_squared_error: 0.0095 - val_loss: 0.0100 - val_encode_out_loss: 7.7452e-04 - val_decode_out_loss: 0.0092 - val_encode_out_mean_squared_error: 7.7452e-04 - val_decode_out_mean_squared_error: 0.0092\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0096 - encode_out_loss: 6.3321e-04 - decode_out_loss: 0.0090 - encode_out_mean_squared_error: 6.3321e-04 - decode_out_mean_squared_error: 0.0090 - val_loss: 0.0094 - val_encode_out_loss: 5.8664e-04 - val_decode_out_loss: 0.0088 - val_encode_out_mean_squared_error: 5.8664e-04 - val_decode_out_mean_squared_error: 0.0088\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 0.0093 - encode_out_loss: 5.9565e-04 - decode_out_loss: 0.0087 - encode_out_mean_squared_error: 5.9565e-04 - decode_out_mean_squared_error: 0.0087 - val_loss: 0.0091 - val_encode_out_loss: 5.0558e-04 - val_decode_out_loss: 0.0086 - val_encode_out_mean_squared_error: 5.0558e-04 - val_decode_out_mean_squared_error: 0.0086\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.0091 - encode_out_loss: 5.5462e-04 - decode_out_loss: 0.0086 - encode_out_mean_squared_error: 5.5462e-04 - decode_out_mean_squared_error: 0.0086 - val_loss: 0.0088 - val_encode_out_loss: 4.8515e-04 - val_decode_out_loss: 0.0083 - val_encode_out_mean_squared_error: 4.8515e-04 - val_decode_out_mean_squared_error: 0.0083\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 1s 280us/step - loss: 0.0089 - encode_out_loss: 5.6083e-04 - decode_out_loss: 0.0084 - encode_out_mean_squared_error: 5.6083e-04 - decode_out_mean_squared_error: 0.0084 - val_loss: 0.0088 - val_encode_out_loss: 5.2416e-04 - val_decode_out_loss: 0.0083 - val_encode_out_mean_squared_error: 5.2416e-04 - val_decode_out_mean_squared_error: 0.0083\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 1s 284us/step - loss: 0.0088 - encode_out_loss: 5.5783e-04 - decode_out_loss: 0.0082 - encode_out_mean_squared_error: 5.5783e-04 - decode_out_mean_squared_error: 0.0082 - val_loss: 0.0085 - val_encode_out_loss: 4.9998e-04 - val_decode_out_loss: 0.0080 - val_encode_out_mean_squared_error: 4.9998e-04 - val_decode_out_mean_squared_error: 0.0080\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0086 - encode_out_loss: 5.3421e-04 - decode_out_loss: 0.0081 - encode_out_mean_squared_error: 5.3421e-04 - decode_out_mean_squared_error: 0.0081 - val_loss: 0.0085 - val_encode_out_loss: 5.6163e-04 - val_decode_out_loss: 0.0080 - val_encode_out_mean_squared_error: 5.6163e-04 - val_decode_out_mean_squared_error: 0.0080\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 0.0086 - encode_out_loss: 5.6026e-04 - decode_out_loss: 0.0080 - encode_out_mean_squared_error: 5.6026e-04 - decode_out_mean_squared_error: 0.0080 - val_loss: 0.0083 - val_encode_out_loss: 5.6352e-04 - val_decode_out_loss: 0.0077 - val_encode_out_mean_squared_error: 5.6352e-04 - val_decode_out_mean_squared_error: 0.0077\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.0085 - encode_out_loss: 5.8388e-04 - decode_out_loss: 0.0079 - encode_out_mean_squared_error: 5.8388e-04 - decode_out_mean_squared_error: 0.0079 - val_loss: 0.0081 - val_encode_out_loss: 4.3348e-04 - val_decode_out_loss: 0.0077 - val_encode_out_mean_squared_error: 4.3348e-04 - val_decode_out_mean_squared_error: 0.0077\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 0.0083 - encode_out_loss: 5.2030e-04 - decode_out_loss: 0.0078 - encode_out_mean_squared_error: 5.2030e-04 - decode_out_mean_squared_error: 0.0078 - val_loss: 0.0081 - val_encode_out_loss: 5.4214e-04 - val_decode_out_loss: 0.0075 - val_encode_out_mean_squared_error: 5.4214e-04 - val_decode_out_mean_squared_error: 0.0075\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 0.0083 - encode_out_loss: 5.6047e-04 - decode_out_loss: 0.0078 - encode_out_mean_squared_error: 5.6047e-04 - decode_out_mean_squared_error: 0.0078 - val_loss: 0.0080 - val_encode_out_loss: 4.9994e-04 - val_decode_out_loss: 0.0075 - val_encode_out_mean_squared_error: 4.9994e-04 - val_decode_out_mean_squared_error: 0.0075\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 1s 287us/step - loss: 0.0083 - encode_out_loss: 5.6332e-04 - decode_out_loss: 0.0077 - encode_out_mean_squared_error: 5.6332e-04 - decode_out_mean_squared_error: 0.0077 - val_loss: 0.0080 - val_encode_out_loss: 5.1778e-04 - val_decode_out_loss: 0.0075 - val_encode_out_mean_squared_error: 5.1778e-04 - val_decode_out_mean_squared_error: 0.0075\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.0082 - encode_out_loss: 5.8288e-04 - decode_out_loss: 0.0077 - encode_out_mean_squared_error: 5.8288e-04 - decode_out_mean_squared_error: 0.0077 - val_loss: 0.0080 - val_encode_out_loss: 5.4616e-04 - val_decode_out_loss: 0.0074 - val_encode_out_mean_squared_error: 5.4616e-04 - val_decode_out_mean_squared_error: 0.0074\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 1s 285us/step - loss: 0.0082 - encode_out_loss: 5.7127e-04 - decode_out_loss: 0.0076 - encode_out_mean_squared_error: 5.7127e-04 - decode_out_mean_squared_error: 0.0076 - val_loss: 0.0078 - val_encode_out_loss: 4.6239e-04 - val_decode_out_loss: 0.0073 - val_encode_out_mean_squared_error: 4.6239e-04 - val_decode_out_mean_squared_error: 0.0073\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0080 - encode_out_loss: 5.3094e-04 - decode_out_loss: 0.0075 - encode_out_mean_squared_error: 5.3094e-04 - decode_out_mean_squared_error: 0.0075 - val_loss: 0.0078 - val_encode_out_loss: 5.9597e-04 - val_decode_out_loss: 0.0072 - val_encode_out_mean_squared_error: 5.9597e-04 - val_decode_out_mean_squared_error: 0.0072\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.0080 - encode_out_loss: 5.3249e-04 - decode_out_loss: 0.0074 - encode_out_mean_squared_error: 5.3249e-04 - decode_out_mean_squared_error: 0.0074 - val_loss: 0.0077 - val_encode_out_loss: 4.5153e-04 - val_decode_out_loss: 0.0072 - val_encode_out_mean_squared_error: 4.5153e-04 - val_decode_out_mean_squared_error: 0.0072\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0079 - encode_out_loss: 5.3707e-04 - decode_out_loss: 0.0074 - encode_out_mean_squared_error: 5.3707e-04 - decode_out_mean_squared_error: 0.0074 - val_loss: 0.0078 - val_encode_out_loss: 5.6047e-04 - val_decode_out_loss: 0.0072 - val_encode_out_mean_squared_error: 5.6047e-04 - val_decode_out_mean_squared_error: 0.0072\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 1s 287us/step - loss: 0.0078 - encode_out_loss: 5.4636e-04 - decode_out_loss: 0.0073 - encode_out_mean_squared_error: 5.4636e-04 - decode_out_mean_squared_error: 0.0073 - val_loss: 0.0075 - val_encode_out_loss: 5.6807e-04 - val_decode_out_loss: 0.0069 - val_encode_out_mean_squared_error: 5.6807e-04 - val_decode_out_mean_squared_error: 0.0069\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 0.0078 - encode_out_loss: 5.6923e-04 - decode_out_loss: 0.0072 - encode_out_mean_squared_error: 5.6923e-04 - decode_out_mean_squared_error: 0.0072 - val_loss: 0.0077 - val_encode_out_loss: 7.4630e-04 - val_decode_out_loss: 0.0069 - val_encode_out_mean_squared_error: 7.4630e-04 - val_decode_out_mean_squared_error: 0.0069\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.0077 - encode_out_loss: 5.6806e-04 - decode_out_loss: 0.0071 - encode_out_mean_squared_error: 5.6806e-04 - decode_out_mean_squared_error: 0.0071 - val_loss: 0.0074 - val_encode_out_loss: 5.0548e-04 - val_decode_out_loss: 0.0068 - val_encode_out_mean_squared_error: 5.0548e-04 - val_decode_out_mean_squared_error: 0.0068\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.0076 - encode_out_loss: 5.8221e-04 - decode_out_loss: 0.0070 - encode_out_mean_squared_error: 5.8221e-04 - decode_out_mean_squared_error: 0.0070 - val_loss: 0.0074 - val_encode_out_loss: 6.6410e-04 - val_decode_out_loss: 0.0067 - val_encode_out_mean_squared_error: 6.6410e-04 - val_decode_out_mean_squared_error: 0.0067\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.0075 - encode_out_loss: 5.6927e-04 - decode_out_loss: 0.0069 - encode_out_mean_squared_error: 5.6927e-04 - decode_out_mean_squared_error: 0.0069 - val_loss: 0.0072 - val_encode_out_loss: 5.9921e-04 - val_decode_out_loss: 0.0066 - val_encode_out_mean_squared_error: 5.9921e-04 - val_decode_out_mean_squared_error: 0.0066\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0074 - encode_out_loss: 5.9999e-04 - decode_out_loss: 0.0068 - encode_out_mean_squared_error: 5.9999e-04 - decode_out_mean_squared_error: 0.0068 - val_loss: 0.0072 - val_encode_out_loss: 7.1768e-04 - val_decode_out_loss: 0.0065 - val_encode_out_mean_squared_error: 7.1768e-04 - val_decode_out_mean_squared_error: 0.0065\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 0.0073 - encode_out_loss: 6.1343e-04 - decode_out_loss: 0.0067 - encode_out_mean_squared_error: 6.1343e-04 - decode_out_mean_squared_error: 0.0067 - val_loss: 0.0069 - val_encode_out_loss: 5.9677e-04 - val_decode_out_loss: 0.0064 - val_encode_out_mean_squared_error: 5.9677e-04 - val_decode_out_mean_squared_error: 0.0064\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0073 - encode_out_loss: 6.2904e-04 - decode_out_loss: 0.0066 - encode_out_mean_squared_error: 6.2904e-04 - decode_out_mean_squared_error: 0.0066 - val_loss: 0.0068 - val_encode_out_loss: 5.7382e-04 - val_decode_out_loss: 0.0062 - val_encode_out_mean_squared_error: 5.7382e-04 - val_decode_out_mean_squared_error: 0.0062\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0071 - encode_out_loss: 5.9935e-04 - decode_out_loss: 0.0065 - encode_out_mean_squared_error: 5.9935e-04 - decode_out_mean_squared_error: 0.0065 - val_loss: 0.0069 - val_encode_out_loss: 6.0966e-04 - val_decode_out_loss: 0.0063 - val_encode_out_mean_squared_error: 6.0966e-04 - val_decode_out_mean_squared_error: 0.0063\n",
      "Epoch 33/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0071 - encode_out_loss: 6.4208e-04 - decode_out_loss: 0.0065 - encode_out_mean_squared_error: 6.4208e-04 - decode_out_mean_squared_error: 0.0065 - val_loss: 0.0068 - val_encode_out_loss: 5.7533e-04 - val_decode_out_loss: 0.0062 - val_encode_out_mean_squared_error: 5.7533e-04 - val_decode_out_mean_squared_error: 0.0062\n",
      "Epoch 34/100\n",
      "2000/2000 [==============================] - 1s 288us/step - loss: 0.0071 - encode_out_loss: 6.3660e-04 - decode_out_loss: 0.0064 - encode_out_mean_squared_error: 6.3660e-04 - decode_out_mean_squared_error: 0.0064 - val_loss: 0.0067 - val_encode_out_loss: 6.2436e-04 - val_decode_out_loss: 0.0061 - val_encode_out_mean_squared_error: 6.2436e-04 - val_decode_out_mean_squared_error: 0.0061\n",
      "Epoch 35/100\n",
      "2000/2000 [==============================] - 1s 301us/step - loss: 0.0070 - encode_out_loss: 6.6664e-04 - decode_out_loss: 0.0063 - encode_out_mean_squared_error: 6.6664e-04 - decode_out_mean_squared_error: 0.0063 - val_loss: 0.0067 - val_encode_out_loss: 5.9121e-04 - val_decode_out_loss: 0.0061 - val_encode_out_mean_squared_error: 5.9121e-04 - val_decode_out_mean_squared_error: 0.0061\n",
      "Epoch 36/100\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.0069 - encode_out_loss: 6.5826e-04 - decode_out_loss: 0.0063 - encode_out_mean_squared_error: 6.5826e-04 - decode_out_mean_squared_error: 0.0063 - val_loss: 0.0065 - val_encode_out_loss: 5.9849e-04 - val_decode_out_loss: 0.0059 - val_encode_out_mean_squared_error: 5.9849e-04 - val_decode_out_mean_squared_error: 0.0059\n",
      "Epoch 37/100\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 0.0068 - encode_out_loss: 6.4494e-04 - decode_out_loss: 0.0062 - encode_out_mean_squared_error: 6.4494e-04 - decode_out_mean_squared_error: 0.0062 - val_loss: 0.0067 - val_encode_out_loss: 7.2794e-04 - val_decode_out_loss: 0.0059 - val_encode_out_mean_squared_error: 7.2794e-04 - val_decode_out_mean_squared_error: 0.0059\n",
      "Epoch 38/100\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 0.0068 - encode_out_loss: 6.4921e-04 - decode_out_loss: 0.0062 - encode_out_mean_squared_error: 6.4921e-04 - decode_out_mean_squared_error: 0.0062 - val_loss: 0.0064 - val_encode_out_loss: 6.1056e-04 - val_decode_out_loss: 0.0058 - val_encode_out_mean_squared_error: 6.1056e-04 - val_decode_out_mean_squared_error: 0.0058\n",
      "Epoch 39/100\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0068 - encode_out_loss: 6.8450e-04 - decode_out_loss: 0.0061 - encode_out_mean_squared_error: 6.8450e-04 - decode_out_mean_squared_error: 0.0061 - val_loss: 0.0063 - val_encode_out_loss: 5.6860e-04 - val_decode_out_loss: 0.0057 - val_encode_out_mean_squared_error: 5.6860e-04 - val_decode_out_mean_squared_error: 0.0057\n",
      "Epoch 40/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0067 - encode_out_loss: 6.2528e-04 - decode_out_loss: 0.0060 - encode_out_mean_squared_error: 6.2528e-04 - decode_out_mean_squared_error: 0.0060 - val_loss: 0.0063 - val_encode_out_loss: 6.3493e-04 - val_decode_out_loss: 0.0057 - val_encode_out_mean_squared_error: 6.3493e-04 - val_decode_out_mean_squared_error: 0.0057\n",
      "Epoch 41/100\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 0.0066 - encode_out_loss: 6.2656e-04 - decode_out_loss: 0.0060 - encode_out_mean_squared_error: 6.2656e-04 - decode_out_mean_squared_error: 0.0060 - val_loss: 0.0063 - val_encode_out_loss: 6.5473e-04 - val_decode_out_loss: 0.0056 - val_encode_out_mean_squared_error: 6.5473e-04 - val_decode_out_mean_squared_error: 0.0056\n",
      "Epoch 42/100\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.0066 - encode_out_loss: 6.8148e-04 - decode_out_loss: 0.0060 - encode_out_mean_squared_error: 6.8148e-04 - decode_out_mean_squared_error: 0.0060 - val_loss: 0.0062 - val_encode_out_loss: 6.4614e-04 - val_decode_out_loss: 0.0056 - val_encode_out_mean_squared_error: 6.4614e-04 - val_decode_out_mean_squared_error: 0.0056\n",
      "Epoch 43/100\n",
      "2000/2000 [==============================] - 1s 306us/step - loss: 0.0065 - encode_out_loss: 6.2042e-04 - decode_out_loss: 0.0059 - encode_out_mean_squared_error: 6.2042e-04 - decode_out_mean_squared_error: 0.0059 - val_loss: 0.0061 - val_encode_out_loss: 5.5317e-04 - val_decode_out_loss: 0.0056 - val_encode_out_mean_squared_error: 5.5317e-04 - val_decode_out_mean_squared_error: 0.0056\n",
      "Epoch 44/100\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.0065 - encode_out_loss: 6.5241e-04 - decode_out_loss: 0.0059 - encode_out_mean_squared_error: 6.5241e-04 - decode_out_mean_squared_error: 0.0059 - val_loss: 0.0063 - val_encode_out_loss: 6.6035e-04 - val_decode_out_loss: 0.0056 - val_encode_out_mean_squared_error: 6.6035e-04 - val_decode_out_mean_squared_error: 0.0056\n",
      "Epoch 45/100\n",
      "2000/2000 [==============================] - 1s 291us/step - loss: 0.0065 - encode_out_loss: 6.2887e-04 - decode_out_loss: 0.0059 - encode_out_mean_squared_error: 6.2887e-04 - decode_out_mean_squared_error: 0.0059 - val_loss: 0.0061 - val_encode_out_loss: 6.3082e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 6.3082e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 46/100\n",
      "2000/2000 [==============================] - 1s 286us/step - loss: 0.0065 - encode_out_loss: 6.4134e-04 - decode_out_loss: 0.0058 - encode_out_mean_squared_error: 6.4134e-04 - decode_out_mean_squared_error: 0.0058 - val_loss: 0.0061 - val_encode_out_loss: 6.6045e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 6.6045e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 47/100\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 0.0064 - encode_out_loss: 6.4896e-04 - decode_out_loss: 0.0058 - encode_out_mean_squared_error: 6.4896e-04 - decode_out_mean_squared_error: 0.0058 - val_loss: 0.0061 - val_encode_out_loss: 6.8985e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 6.8985e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 48/100\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.0064 - encode_out_loss: 6.4862e-04 - decode_out_loss: 0.0058 - encode_out_mean_squared_error: 6.4862e-04 - decode_out_mean_squared_error: 0.0058 - val_loss: 0.0060 - val_encode_out_loss: 5.4820e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 5.4820e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 49/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0064 - encode_out_loss: 6.2670e-04 - decode_out_loss: 0.0057 - encode_out_mean_squared_error: 6.2670e-04 - decode_out_mean_squared_error: 0.0057 - val_loss: 0.0060 - val_encode_out_loss: 5.4917e-04 - val_decode_out_loss: 0.0055 - val_encode_out_mean_squared_error: 5.4917e-04 - val_decode_out_mean_squared_error: 0.0055\n",
      "Epoch 50/100\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.0063 - encode_out_loss: 5.9774e-04 - decode_out_loss: 0.0057 - encode_out_mean_squared_error: 5.9774e-04 - decode_out_mean_squared_error: 0.0057 - val_loss: 0.0060 - val_encode_out_loss: 6.1933e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 6.1933e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 51/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0063 - encode_out_loss: 6.2039e-04 - decode_out_loss: 0.0057 - encode_out_mean_squared_error: 6.2039e-04 - decode_out_mean_squared_error: 0.0057 - val_loss: 0.0059 - val_encode_out_loss: 6.2313e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.2313e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 52/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0063 - encode_out_loss: 6.1028e-04 - decode_out_loss: 0.0057 - encode_out_mean_squared_error: 6.1028e-04 - decode_out_mean_squared_error: 0.0057 - val_loss: 0.0059 - val_encode_out_loss: 5.5281e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 5.5281e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 53/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0063 - encode_out_loss: 6.3119e-04 - decode_out_loss: 0.0057 - encode_out_mean_squared_error: 6.3119e-04 - decode_out_mean_squared_error: 0.0057 - val_loss: 0.0059 - val_encode_out_loss: 5.2540e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 5.2540e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 54/100\n",
      "2000/2000 [==============================] - 1s 289us/step - loss: 0.0063 - encode_out_loss: 6.1427e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 6.1427e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0062 - val_encode_out_loss: 6.7005e-04 - val_decode_out_loss: 0.0055 - val_encode_out_mean_squared_error: 6.7005e-04 - val_decode_out_mean_squared_error: 0.0055\n",
      "Epoch 55/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0062 - encode_out_loss: 6.0335e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 6.0335e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0058 - val_encode_out_loss: 5.7961e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.7961e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 56/100\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.0062 - encode_out_loss: 5.8503e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 5.8503e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0059 - val_encode_out_loss: 6.3803e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.3803e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 57/100\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0062 - encode_out_loss: 5.8836e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 5.8836e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0059 - val_encode_out_loss: 6.4004e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 6.4004e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 58/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0062 - encode_out_loss: 5.8688e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 5.8688e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0059 - val_encode_out_loss: 5.7850e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 5.7850e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 59/100\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.0061 - encode_out_loss: 5.7850e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 5.7850e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0058 - val_encode_out_loss: 5.0139e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 5.0139e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 60/100\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.0061 - encode_out_loss: 5.6231e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 5.6231e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0058 - val_encode_out_loss: 4.9277e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 4.9277e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 61/100\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.0061 - encode_out_loss: 5.9000e-04 - decode_out_loss: 0.0056 - encode_out_mean_squared_error: 5.9000e-04 - decode_out_mean_squared_error: 0.0056 - val_loss: 0.0059 - val_encode_out_loss: 5.7342e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 5.7342e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 62/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0061 - encode_out_loss: 5.9614e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 5.9614e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0057 - val_encode_out_loss: 4.9292e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 4.9292e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 63/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0061 - encode_out_loss: 5.9432e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 5.9432e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0060 - val_encode_out_loss: 5.6730e-04 - val_decode_out_loss: 0.0054 - val_encode_out_mean_squared_error: 5.6730e-04 - val_decode_out_mean_squared_error: 0.0054\n",
      "Epoch 64/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0061 - encode_out_loss: 5.8055e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 5.8055e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0058 - val_encode_out_loss: 4.8115e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 4.8115e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 65/100\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0061 - encode_out_loss: 5.8136e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 5.8136e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0058 - val_encode_out_loss: 5.4878e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.4878e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 66/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0061 - encode_out_loss: 6.1134e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 6.1134e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0059 - val_encode_out_loss: 7.8939e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 7.8939e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 67/100\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 0.0060 - encode_out_loss: 5.8432e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 5.8432e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0056 - val_encode_out_loss: 5.0459e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.0459e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 68/100\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.0060 - encode_out_loss: 5.8088e-04 - decode_out_loss: 0.0055 - encode_out_mean_squared_error: 5.8088e-04 - decode_out_mean_squared_error: 0.0055 - val_loss: 0.0057 - val_encode_out_loss: 5.1055e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.1055e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 69/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0060 - encode_out_loss: 5.4170e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 5.4170e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0057 - val_encode_out_loss: 6.0479e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 6.0479e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 70/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0060 - encode_out_loss: 5.8911e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 5.8911e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0056 - val_encode_out_loss: 5.3623e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.3623e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 71/100\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.0060 - encode_out_loss: 5.5922e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 5.5922e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0056 - val_encode_out_loss: 4.7797e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 4.7797e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 72/100\n",
      "2000/2000 [==============================] - 1s 302us/step - loss: 0.0060 - encode_out_loss: 5.7505e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 5.7505e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0057 - val_encode_out_loss: 4.7524e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 4.7524e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 73/100\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 0.0060 - encode_out_loss: 5.6445e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 5.6445e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0056 - val_encode_out_loss: 4.9300e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 4.9300e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 74/100\n",
      "2000/2000 [==============================] - 1s 298us/step - loss: 0.0060 - encode_out_loss: 5.7074e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 5.7074e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0056 - val_encode_out_loss: 5.1460e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.1460e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 75/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0059 - encode_out_loss: 5.5605e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 5.5605e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0057 - val_encode_out_loss: 5.3807e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.3807e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 76/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0059 - encode_out_loss: 5.5585e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.5585e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0056 - val_encode_out_loss: 4.7475e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 4.7475e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 77/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0059 - encode_out_loss: 5.4816e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.4816e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0058 - val_encode_out_loss: 5.3976e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 5.3976e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 78/100\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.0059 - encode_out_loss: 5.4791e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.4791e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0059 - val_encode_out_loss: 5.9135e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 5.9135e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 79/100\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0059 - encode_out_loss: 5.5005e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.5005e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0055 - val_encode_out_loss: 4.9245e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 4.9245e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 80/100\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 0.0058 - encode_out_loss: 5.4387e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.4387e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0057 - val_encode_out_loss: 4.9000e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 4.9000e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 81/100\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.0059 - encode_out_loss: 5.5930e-04 - decode_out_loss: 0.0054 - encode_out_mean_squared_error: 5.5930e-04 - decode_out_mean_squared_error: 0.0054 - val_loss: 0.0056 - val_encode_out_loss: 4.8363e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 4.8363e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 82/100\n",
      "2000/2000 [==============================] - 1s 290us/step - loss: 0.0058 - encode_out_loss: 5.3899e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.3899e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0056 - val_encode_out_loss: 5.1168e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.1168e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 83/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0058 - encode_out_loss: 5.3699e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.3699e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0057 - val_encode_out_loss: 5.7812e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.7812e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 84/100\n",
      "2000/2000 [==============================] - 1s 299us/step - loss: 0.0058 - encode_out_loss: 5.4940e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.4940e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0055 - val_encode_out_loss: 4.7894e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 4.7894e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 85/100\n",
      "2000/2000 [==============================] - 1s 305us/step - loss: 0.0058 - encode_out_loss: 5.5674e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.5674e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0054 - val_encode_out_loss: 4.6313e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 4.6313e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 86/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0058 - encode_out_loss: 5.3433e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.3433e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0057 - val_encode_out_loss: 5.4507e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 5.4507e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 87/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0058 - encode_out_loss: 5.3870e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.3870e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0055 - val_encode_out_loss: 4.5613e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 4.5613e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 88/100\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.0058 - encode_out_loss: 5.4146e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.4146e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0056 - val_encode_out_loss: 5.9097e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 5.9097e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 89/100\n",
      "2000/2000 [==============================] - 1s 294us/step - loss: 0.0058 - encode_out_loss: 5.3375e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.3375e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0056 - val_encode_out_loss: 5.9584e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 5.9584e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 90/100\n",
      "2000/2000 [==============================] - 1s 292us/step - loss: 0.0058 - encode_out_loss: 5.3495e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.3495e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0056 - val_encode_out_loss: 4.9129e-04 - val_decode_out_loss: 0.0051 - val_encode_out_mean_squared_error: 4.9129e-04 - val_decode_out_mean_squared_error: 0.0051\n",
      "Epoch 91/100\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.0058 - encode_out_loss: 5.5549e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.5549e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0055 - val_encode_out_loss: 4.9068e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 4.9068e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 92/100\n",
      "2000/2000 [==============================] - 1s 304us/step - loss: 0.0057 - encode_out_loss: 5.0564e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.0564e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0055 - val_encode_out_loss: 5.1532e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 5.1532e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 93/100\n",
      "2000/2000 [==============================] - 1s 295us/step - loss: 0.0057 - encode_out_loss: 5.1680e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.1680e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0058 - val_encode_out_loss: 4.9169e-04 - val_decode_out_loss: 0.0053 - val_encode_out_mean_squared_error: 4.9169e-04 - val_decode_out_mean_squared_error: 0.0053\n",
      "Epoch 94/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0058 - encode_out_loss: 5.5111e-04 - decode_out_loss: 0.0053 - encode_out_mean_squared_error: 5.5111e-04 - decode_out_mean_squared_error: 0.0053 - val_loss: 0.0053 - val_encode_out_loss: 4.4375e-04 - val_decode_out_loss: 0.0049 - val_encode_out_mean_squared_error: 4.4375e-04 - val_decode_out_mean_squared_error: 0.0049\n",
      "Epoch 95/100\n",
      "2000/2000 [==============================] - 1s 296us/step - loss: 0.0058 - encode_out_loss: 5.4286e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.4286e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0059 - val_encode_out_loss: 7.1403e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 7.1403e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 96/100\n",
      "2000/2000 [==============================] - 1s 303us/step - loss: 0.0057 - encode_out_loss: 5.0916e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.0916e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0056 - val_encode_out_loss: 4.8201e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 4.8201e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 97/100\n",
      "2000/2000 [==============================] - 1s 300us/step - loss: 0.0057 - encode_out_loss: 5.1183e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.1183e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0055 - val_encode_out_loss: 5.5645e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 5.5645e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 98/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0057 - encode_out_loss: 5.5559e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.5559e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0057 - val_encode_out_loss: 5.2585e-04 - val_decode_out_loss: 0.0052 - val_encode_out_mean_squared_error: 5.2585e-04 - val_decode_out_mean_squared_error: 0.0052\n",
      "Epoch 99/100\n",
      "2000/2000 [==============================] - 1s 293us/step - loss: 0.0057 - encode_out_loss: 5.3883e-04 - decode_out_loss: 0.0052 - encode_out_mean_squared_error: 5.3883e-04 - decode_out_mean_squared_error: 0.0052 - val_loss: 0.0055 - val_encode_out_loss: 5.1063e-04 - val_decode_out_loss: 0.0050 - val_encode_out_mean_squared_error: 5.1063e-04 - val_decode_out_mean_squared_error: 0.0050\n",
      "Epoch 100/100\n",
      "2000/2000 [==============================] - 1s 297us/step - loss: 0.0056 - encode_out_loss: 5.0503e-04 - decode_out_loss: 0.0051 - encode_out_mean_squared_error: 5.0503e-04 - decode_out_mean_squared_error: 0.0051 - val_loss: 0.0054 - val_encode_out_loss: 4.5123e-04 - val_decode_out_loss: 0.0049 - val_encode_out_mean_squared_error: 4.5123e-04 - val_decode_out_mean_squared_error: 0.0049\n"
     ]
    }
   ],
   "source": [
    "history=autoencoder.fit(Y_scaled_train,[X_scaled_train, Y_scaled_train],\n",
    "                shuffle=True,\n",
    "                epochs=100,\n",
    "                batch_size=8,\n",
    "                validation_data=(Y_scaled_test,[X_scaled_test,Y_scaled_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('autoencoder_model.h5')\n",
    "del autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the previous model and utilise the decoder part to predict the given testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'decode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a3193bffa089>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# load weights from first model by name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoencoder_model.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/MDMachineLearning/lib/python3.6/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1161\u001b[0m                 saving.load_weights_from_hdf5_group_by_name(\n\u001b[1;32m   1162\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_mismatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_mismatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m                     reshape=reshape)\n\u001b[0m\u001b[1;32m   1164\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m                 saving.load_weights_from_hdf5_group(\n",
      "\u001b[0;32m~/.conda/envs/MDMachineLearning/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group_by_name\u001b[0;34m(f, layers, skip_mismatch, reshape)\u001b[0m\n\u001b[1;32m   1081\u001b[0m     \"\"\"\n\u001b[1;32m   1082\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'keras_version'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1083\u001b[0;31m         \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keras_version'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1084\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m         \u001b[0moriginal_keras_version\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'decode'"
     ]
    }
   ],
   "source": [
    "# generator, from latent space to reconstructed inputs\n",
    "decoder_input = Input(shape=(latent_dim,))\n",
    "#decoded_h = Dense(intermediate_dim, activation=\"relu\", name=\"hiddenLayer2\")(decoder_input)\n",
    "#decoded = Dense(original_dim, activation='relu', name=\"decode_out\")(decoded_h)\n",
    "\n",
    "decoded_h_1= Dense(intermediate_dim_1,kernel_initializer='normal', activation='relu', name=\"hiddenLayer4\")(decoder_input)\n",
    "decoded_h_2= Dense(intermediate_dim_2,kernel_initializer='normal', activation='relu', name=\"hiddenLayer5\")(decoded_h_1)\n",
    "decoded_h_3= Dense(intermediate_dim_3,kernel_initializer='normal', activation='relu', name=\"hiddenLayer6\")(decoded_h_2)\n",
    "decoded = Dense(original_dim,kernel_initializer='normal', activation='sigmoid', name=\"decode_out\")(decoded_h_3)\n",
    "\n",
    "generator = Model(decoder_input, decoded)\n",
    "# load weights from first model by name\n",
    "generator.load_weights('autoencoder_model.h5', by_name=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the training and testing loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2ad1dfb91320>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(211)\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 2)                 0         \n",
      "_________________________________________________________________\n",
      "hiddenLayer4 (Dense)         (None, 16)                48        \n",
      "_________________________________________________________________\n",
      "hiddenLayer5 (Dense)         (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "hiddenLayer6 (Dense)         (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "decode_out (Dense)           (None, 198)               12870     \n",
      "=================================================================\n",
      "Total params: 15,574\n",
      "Trainable params: 15,574\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 2), (500, 198))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_test.shape, Y_scaled_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the 7 testing structures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset=pd.read_csv('./Ala13/new_testing_data_7.csv',names=['PCA1','PCA2'])\n",
    "predict_dataset.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_dataset=scalar1.transform(predict_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict the 7 testing structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.4999922  0.5000041  0.49997604 ... 0.5000143  0.49998653 0.49999666]\n",
      " [0.49996197 0.5000227  0.49992526 ... 0.50005776 0.49994063 0.49997902]\n",
      " [0.4999473  0.50003785 0.4999086  ... 0.5000867  0.49991596 0.4999671 ]\n",
      " ...\n",
      " [0.49999774 0.5000384  0.499947   ... 0.5000521  0.49992335 0.4999714 ]\n",
      " [0.49999917 0.5000425  0.49994493 ... 0.5000562  0.49990538 0.4999606 ]\n",
      " [0.49999833 0.5000173  0.49997813 ... 0.50002474 0.4999529  0.49997926]]\n"
     ]
    }
   ],
   "source": [
    "pred=generator.predict(predict_dataset, batch_size=16)\n",
    "print(pred)\n",
    "save=pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=scalar2.inverse_transform(save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30.26544 , 31.88873 , 29.635094, ..., 24.582815, 20.604979,\n",
       "        21.583393],\n",
       "       [30.26513 , 31.888872, 29.63453 , ..., 24.583752, 20.604136,\n",
       "        21.583044],\n",
       "       [30.26498 , 31.888988, 29.634342, ..., 24.584375, 20.603683,\n",
       "        21.58281 ],\n",
       "       ...,\n",
       "       [30.265495, 31.888992, 29.63477 , ..., 24.583628, 20.603819,\n",
       "        21.582895],\n",
       "       [30.26551 , 31.88902 , 29.634747, ..., 24.583717, 20.603489,\n",
       "        21.58268 ],\n",
       "       [30.265503, 31.888828, 29.635118, ..., 24.58304 , 20.604362,\n",
       "        21.58305 ]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=pd.DataFrame(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>188</th>\n",
       "      <th>189</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30.265440</td>\n",
       "      <td>31.888729</td>\n",
       "      <td>29.635094</td>\n",
       "      <td>30.148331</td>\n",
       "      <td>31.843025</td>\n",
       "      <td>29.922089</td>\n",
       "      <td>30.114326</td>\n",
       "      <td>31.393517</td>\n",
       "      <td>29.950163</td>\n",
       "      <td>30.119411</td>\n",
       "      <td>...</td>\n",
       "      <td>21.755301</td>\n",
       "      <td>24.324160</td>\n",
       "      <td>20.522970</td>\n",
       "      <td>21.855049</td>\n",
       "      <td>24.417492</td>\n",
       "      <td>20.591421</td>\n",
       "      <td>22.188961</td>\n",
       "      <td>24.582815</td>\n",
       "      <td>20.604979</td>\n",
       "      <td>21.583393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30.265129</td>\n",
       "      <td>31.888872</td>\n",
       "      <td>29.634529</td>\n",
       "      <td>30.148327</td>\n",
       "      <td>31.842598</td>\n",
       "      <td>29.922001</td>\n",
       "      <td>30.114237</td>\n",
       "      <td>31.393717</td>\n",
       "      <td>29.949099</td>\n",
       "      <td>30.119822</td>\n",
       "      <td>...</td>\n",
       "      <td>21.755257</td>\n",
       "      <td>24.323568</td>\n",
       "      <td>20.522905</td>\n",
       "      <td>21.856215</td>\n",
       "      <td>24.417107</td>\n",
       "      <td>20.591307</td>\n",
       "      <td>22.189987</td>\n",
       "      <td>24.583752</td>\n",
       "      <td>20.604136</td>\n",
       "      <td>21.583044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30.264980</td>\n",
       "      <td>31.888988</td>\n",
       "      <td>29.634342</td>\n",
       "      <td>30.148325</td>\n",
       "      <td>31.842390</td>\n",
       "      <td>29.921965</td>\n",
       "      <td>30.114161</td>\n",
       "      <td>31.393692</td>\n",
       "      <td>29.948618</td>\n",
       "      <td>30.119944</td>\n",
       "      <td>...</td>\n",
       "      <td>21.755262</td>\n",
       "      <td>24.323299</td>\n",
       "      <td>20.522976</td>\n",
       "      <td>21.856726</td>\n",
       "      <td>24.416952</td>\n",
       "      <td>20.591352</td>\n",
       "      <td>22.190575</td>\n",
       "      <td>24.584375</td>\n",
       "      <td>20.603683</td>\n",
       "      <td>21.582809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30.265509</td>\n",
       "      <td>31.889017</td>\n",
       "      <td>29.634752</td>\n",
       "      <td>30.148378</td>\n",
       "      <td>31.842648</td>\n",
       "      <td>29.921673</td>\n",
       "      <td>30.114033</td>\n",
       "      <td>31.393520</td>\n",
       "      <td>29.949329</td>\n",
       "      <td>30.119621</td>\n",
       "      <td>...</td>\n",
       "      <td>21.755716</td>\n",
       "      <td>24.323648</td>\n",
       "      <td>20.523434</td>\n",
       "      <td>21.855877</td>\n",
       "      <td>24.417381</td>\n",
       "      <td>20.591640</td>\n",
       "      <td>22.190439</td>\n",
       "      <td>24.583696</td>\n",
       "      <td>20.603582</td>\n",
       "      <td>21.582741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30.265495</td>\n",
       "      <td>31.888992</td>\n",
       "      <td>29.634769</td>\n",
       "      <td>30.148424</td>\n",
       "      <td>31.842684</td>\n",
       "      <td>29.921755</td>\n",
       "      <td>30.114086</td>\n",
       "      <td>31.393465</td>\n",
       "      <td>29.949442</td>\n",
       "      <td>30.119570</td>\n",
       "      <td>...</td>\n",
       "      <td>21.755585</td>\n",
       "      <td>24.323832</td>\n",
       "      <td>20.523298</td>\n",
       "      <td>21.855764</td>\n",
       "      <td>24.417446</td>\n",
       "      <td>20.591536</td>\n",
       "      <td>22.190201</td>\n",
       "      <td>24.583628</td>\n",
       "      <td>20.603819</td>\n",
       "      <td>21.582895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>30.265511</td>\n",
       "      <td>31.889021</td>\n",
       "      <td>29.634747</td>\n",
       "      <td>30.148357</td>\n",
       "      <td>31.842636</td>\n",
       "      <td>29.921646</td>\n",
       "      <td>30.114016</td>\n",
       "      <td>31.393539</td>\n",
       "      <td>29.949289</td>\n",
       "      <td>30.119638</td>\n",
       "      <td>...</td>\n",
       "      <td>21.755774</td>\n",
       "      <td>24.323576</td>\n",
       "      <td>20.523487</td>\n",
       "      <td>21.855907</td>\n",
       "      <td>24.417360</td>\n",
       "      <td>20.591679</td>\n",
       "      <td>22.190525</td>\n",
       "      <td>24.583717</td>\n",
       "      <td>20.603489</td>\n",
       "      <td>21.582680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>30.265503</td>\n",
       "      <td>31.888828</td>\n",
       "      <td>29.635118</td>\n",
       "      <td>30.148281</td>\n",
       "      <td>31.842953</td>\n",
       "      <td>29.921902</td>\n",
       "      <td>30.114225</td>\n",
       "      <td>31.393440</td>\n",
       "      <td>29.950041</td>\n",
       "      <td>30.119400</td>\n",
       "      <td>...</td>\n",
       "      <td>21.755646</td>\n",
       "      <td>24.323936</td>\n",
       "      <td>20.523232</td>\n",
       "      <td>21.855217</td>\n",
       "      <td>24.417452</td>\n",
       "      <td>20.591669</td>\n",
       "      <td>22.189562</td>\n",
       "      <td>24.583040</td>\n",
       "      <td>20.604362</td>\n",
       "      <td>21.583050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows Ã— 198 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0          1          2          3          4          5    \\\n",
       "0  30.265440  31.888729  29.635094  30.148331  31.843025  29.922089   \n",
       "1  30.265129  31.888872  29.634529  30.148327  31.842598  29.922001   \n",
       "2  30.264980  31.888988  29.634342  30.148325  31.842390  29.921965   \n",
       "3  30.265509  31.889017  29.634752  30.148378  31.842648  29.921673   \n",
       "4  30.265495  31.888992  29.634769  30.148424  31.842684  29.921755   \n",
       "5  30.265511  31.889021  29.634747  30.148357  31.842636  29.921646   \n",
       "6  30.265503  31.888828  29.635118  30.148281  31.842953  29.921902   \n",
       "\n",
       "         6          7          8          9    ...        188        189  \\\n",
       "0  30.114326  31.393517  29.950163  30.119411  ...  21.755301  24.324160   \n",
       "1  30.114237  31.393717  29.949099  30.119822  ...  21.755257  24.323568   \n",
       "2  30.114161  31.393692  29.948618  30.119944  ...  21.755262  24.323299   \n",
       "3  30.114033  31.393520  29.949329  30.119621  ...  21.755716  24.323648   \n",
       "4  30.114086  31.393465  29.949442  30.119570  ...  21.755585  24.323832   \n",
       "5  30.114016  31.393539  29.949289  30.119638  ...  21.755774  24.323576   \n",
       "6  30.114225  31.393440  29.950041  30.119400  ...  21.755646  24.323936   \n",
       "\n",
       "         190        191        192        193        194        195  \\\n",
       "0  20.522970  21.855049  24.417492  20.591421  22.188961  24.582815   \n",
       "1  20.522905  21.856215  24.417107  20.591307  22.189987  24.583752   \n",
       "2  20.522976  21.856726  24.416952  20.591352  22.190575  24.584375   \n",
       "3  20.523434  21.855877  24.417381  20.591640  22.190439  24.583696   \n",
       "4  20.523298  21.855764  24.417446  20.591536  22.190201  24.583628   \n",
       "5  20.523487  21.855907  24.417360  20.591679  22.190525  24.583717   \n",
       "6  20.523232  21.855217  24.417452  20.591669  22.189562  24.583040   \n",
       "\n",
       "         196        197  \n",
       "0  20.604979  21.583393  \n",
       "1  20.604136  21.583044  \n",
       "2  20.603683  21.582809  \n",
       "3  20.603582  21.582741  \n",
       "4  20.603819  21.582895  \n",
       "5  20.603489  21.582680  \n",
       "6  20.604362  21.583050  \n",
       "\n",
       "[7 rows x 198 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the results for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.to_csv('new_results_7.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDMachineLearning",
   "language": "python",
   "name": "mdmachinelearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
