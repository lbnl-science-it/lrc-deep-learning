{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3fb5d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-06 08:26:33.900148: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-06 08:27:04.454393: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import platform\n",
    "import hashlib\n",
    "import pytorch_transformer\n",
    "import re\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformProtein import transformProtein\n",
    "from ProteinDataset import ProteinDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ad9d7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_py3 = platform.python_version()[0] == '3'\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch code for generating from CTRL')\n",
    "\n",
    "#parser.add_argument('--model_dir', type =str, default='model_v0.pth', help='location of training model checkpoint')\n",
    "#parser.add_argument('--model_path', type=str, default='/home/amadani/ctrl/ckpt/seqlen256_36layers_v0.ckpt/model.ckpt-684000', help='location of model *data* checkpoint to load; this is NOT the directory but rather the model checkpoint')\n",
    "\n",
    "parser.add_argument('--model_dir', type =str, default='./checkpoints_cur/finetune_progen_full_demo.pth', help='location of training model checkpoint')\n",
    "parser.add_argument('--model_path', type=str, default='../checkpoints/pretrain_progen_full.pth', help='location of model *data* checkpoint to load; this is NOT the directory but rather the model checkpoint')\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=313,\n",
    "                                        help='random seed for PyTorch, numpy and PythonHash')\n",
    "parser.add_argument('--sequence_len', type=int, default=511*1,\n",
    "                                        help='sequence len of model being fine-tuned')\n",
    "parser.add_argument('--num_epochs', type=int, default=15, help='number of epochs to train for')\n",
    "parser.add_argument('--num_layers', type=int, default=36, help='number of transfomer layers. used for loading checkpoint')\n",
    "parser.add_argument('--batch_size', type=int, default = 4, help='batch size for dataloader')\n",
    "parser.add_argument('--vocab_loc', type=str, default='mapping_files/vocab.txt', help='vocab location')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='for dataloader')\n",
    "parser.add_argument('--warmup_iteration', type=int, default=1000, help='LR warmup cutoff')\n",
    "parser.add_argument('--save_iter', type=int, default=1000, help='save model checkpoint every X iterations')\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0beaa9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ba366b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30008add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----vocab size 129407 ------\n"
     ]
    }
   ],
   "source": [
    "# load the vocabulary from file\n",
    "vocab = open(args.vocab_loc).readlines() if not use_py3 else open(args.vocab_loc, encoding='utf-8').read().split('\\n')[:-1]\n",
    "vocab = list(map(lambda x: x.split(' ')[0], vocab))\n",
    "# length of the vocabulary\n",
    "vocab_size = len(vocab)\n",
    "print('-----vocab size',vocab_size,'------')\n",
    "\n",
    "# define the numericalization map\n",
    "# idx2word maps the numericalized ID to the word\n",
    "# word2idx maps the word to the numericalized ID\n",
    "#word2idx = {u:i for i, u in enumerate(vocab)}\n",
    "#idx2word = np.array(vocab)\n",
    "\n",
    "# sequence length to use for transfomer\n",
    "seq_length = args.sequence_len\n",
    "embedding_dim = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a1c643f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiedEmbeddingSoftmax(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, vocab_size=vocab_size, embedding_size=embedding_dim, **kwargs):\n",
    "    super(TiedEmbeddingSoftmax, self).__init__()\n",
    "    self.w = torch.nn.Parameter(torch.normal(0., 1e-2, size=(vocab_size, embedding_size)))\n",
    "    self.b = torch.nn.Parameter(torch.zeros(vocab_size))\n",
    "\n",
    "  def forward(self, inputs, embed=True):\n",
    "    if embed:\n",
    "      return torch.nn.functional.embedding(inputs, self.w)\n",
    "    else:\n",
    "      return torch.tensordot(inputs, self.w.t(), 1) + self.b\n",
    "\n",
    "class CTRLmodel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CTRLmodel,self).__init__()\n",
    "    self.tied_embedding_softmax = TiedEmbeddingSoftmax()\n",
    "    self.encoder = pytorch_transformer.Encoder()\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    x = self.tied_embedding_softmax(inputs, embed = True)\n",
    "    x = self.encoder(x)\n",
    "    x = self.tied_embedding_softmax(x, embed = False)\n",
    "    return x\n",
    "\n",
    "  def loadCheckpoint(self, model_path, num_layers):\n",
    "    #pytorch_model_hash = hashlib.md5(model_path.encode('utf-8')).hexdigest()\n",
    "    pytorch_model_hash = model_path\n",
    "\n",
    "    if os.path.exists(pytorch_model_hash):\n",
    "      print('Found PyTorch checkpoint @', pytorch_model_hash)\n",
    "      print('Loading instead of converting from TensorFlow')\n",
    "      checkpoint = torch.load(pytorch_model_hash)\n",
    "      \n",
    "      #self.tied_embedding_softmax.load_state_dict(checkpoint['softmax'])\n",
    "      #self.encoder.load_state_dict(checkpoint['encoder'])\n",
    "      ## load state dict has KeyError, because checkpoint is ready the state_dict\n",
    "      ## can load checkpoint directly \n",
    "      ## https://discuss.pytorch.org/t/keyerror-state-dict/18220/5\n",
    "      self.load_state_dict(checkpoint)\n",
    "\n",
    "      #self.tied_embedding_softmax.to('cuda')\n",
    "      #self.encoder.to('cuda')\n",
    "      self.tied_embedding_softmax.to(DEVICE)\n",
    "      self.encoder.to(DEVICE)\n",
    "\n",
    "    else:\n",
    "      print('Error: Could not find PyTorch checkpoint')\n",
    "      sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16f2ed33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized\n"
     ]
    }
   ],
   "source": [
    "# initialize ctrl object\n",
    "model = CTRLmodel()\n",
    "print('model initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3376cf99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PyTorch checkpoint @ ../checkpoints/pretrain_progen_full.pth\n",
      "Loading instead of converting from TensorFlow\n",
      "previous checkpoint loaded\n"
     ]
    }
   ],
   "source": [
    "# load checkpoint with args.model_path\n",
    "model.loadCheckpoint(model_path=args.model_path, num_layers = args.num_layers)\n",
    "print('previous checkpoint loaded')\n",
    "#model = model.cuda()\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05bfb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all weights except embedding\n",
    "for p in model.parameters():\n",
    "    p.requires_grad=False\n",
    "model.tied_embedding_softmax.w.requires_grad=True\n",
    "model.tied_embedding_softmax.b.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64a4a3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, warmup_iteration, seq_length, batch_size, num_workers, vocab_size, model_dir, save_iter, pklpath):\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.model_dir = model_dir\n",
    "        self.save_iter = save_iter\n",
    "        self.pklpath = pklpath\n",
    "        self.firstAAidx = self.vocab_size - 26 # Assuming that the pad token is the last token and AAs are at the end\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters()) #lr, betas\n",
    "        lambdafn = lambda iteration: min(iteration/(warmup_iteration*1.0),1.0)\n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lambdafn)\n",
    "        \n",
    "        self.criterion = torch.nn.CrossEntropyLoss(ignore_index=self.vocab_size-1, reduction='none')\n",
    "        \n",
    "        self.transformFull = transformProtein(maxSampleLength = seq_length+1, \n",
    "                                              selectSwiss = 1.0, selectTrembl = 0, \n",
    "                                              maxTaxaPerSample = 3, maxKwPerSample = 5, dropRate = 0.2)\n",
    "        self.transformPartial = transformProtein(maxSampleLength = seq_length+1,   \n",
    "                                                 selectSwiss = 1.0, selectTrembl = 0,\n",
    "                                                 maxTaxaPerSample = 3, maxKwPerSample = 5, dropRate = 0.2)\n",
    "        self.transformNone = transformProtein(maxSampleLength = seq_length+1,   \n",
    "                                              selectSwiss = 1.0, selectTrembl = 0,\n",
    "                                              maxTaxaPerSample = 3, maxKwPerSample = 5, dropRate = 0.2)\n",
    "        \n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        self.model.train()\n",
    "\n",
    "        iter_num = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            loss_e = 0.0\n",
    "            num_e = 0\n",
    "\n",
    "            for chunknum in range(1):\n",
    "                #pklpath = '../miBIG/mibig_train_new2.p'\n",
    "                #pklpath = '../miBIG/mibig_train_new.p'\n",
    "                chunk_dataset = ProteinDataset(self.pklpath, firstAAidx = self.firstAAidx, transformFull = self.transformFull, \n",
    "                                               transformPartial = self.transformPartial, transformNone = self.transformNone)\n",
    "                dataloader = DataLoader(chunk_dataset, shuffle = True, batch_size = self.batch_size,\n",
    "                                        num_workers = self.num_workers, pin_memory = False) #TODO pinmem?\n",
    "                \n",
    "                for i, (sample, labels, existence, padIndex, begAAindex) in enumerate(dataloader):\n",
    "                    self.optimizer.zero_grad()\n",
    "                    #sample, labels, existence, padIndex = sample.cuda(), labels.cuda(), existence.cuda(), padIndex.cuda()\n",
    "                    sample, labels, existence, padIndex = sample.to(DEVICE), labels.to(DEVICE), existence.to(DEVICE), padIndex.to(DEVICE)\n",
    "                    output = self.model(sample)\n",
    "                    #pdb.set_trace()\n",
    "                    loss = self.criterion(output.permute(0,2,1), labels)\n",
    "                    loss = torch.mean((torch.sum(loss,dim=1)/padIndex)*existence) #pad masking, loss weighting\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.25)\n",
    "                    self.optimizer.step()\n",
    "                    self.scheduler.step()\n",
    "                    loss_e += loss.item()\n",
    "                    num_e += sample.shape[0]\n",
    "                    iter_num += 1\n",
    "                    self.writer.add_scalar('Loss_iteration',loss.item(),iter_num)\n",
    "\n",
    "                    if (iter_num+1)%self.save_iter==0 or (epoch+1==num_epochs):\n",
    "                        torch.save({'epoch': epoch, 'chunknum': chunknum, 'iteration':iter_num,\n",
    "                                    'model_state_dict': self.model.state_dict(),\n",
    "                                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                                    'loss': loss,\n",
    "                                   }, self.model_dir)\n",
    "                loss_e/=num_e\n",
    "            print(\"Epoch: {0} ; loss_e: {1}\".format(epoch, loss_e))\n",
    "            self.writer.add_scalar('Loss_epoch',loss_e, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b38a52a1",
   "metadata": {},
   "source": [
    "## BGC training samples on S3:\n",
    "`aws s3 ls s3://share.jgi-ga.org/satria/for_bgc_gpt/ --recursive`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc252c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle\n",
    "\n",
    "# Read JSON data from file\n",
    "with open('../miBIG/S3/data-1.json', 'r') as json_file:\n",
    "    json_data = json.load(json_file)\n",
    "\n",
    "json_dict = {}\n",
    "for k in range(len(json_data[:1000])):\n",
    "    d = json_data[k]\n",
    "    d['seq'] = d['seq'].replace(' ', 'B')\n",
    "    list(d['swiss'].keys())[0]\n",
    "    uid = 'BGC' + list(d['swiss'].keys())[0] + '-' + str(k)\n",
    "    json_dict[uid] = d\n",
    "\n",
    "# Convert Python object to pickle\n",
    "with open('../miBIG/S3_pickle/data-1.pickle', 'wb') as pickle_file:\n",
    "    pickle.dump(json_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "00c0d5c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using one unified encoder to represent protein sample with length 129406\n",
      "training data size: 1000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##########################################################\n",
    "# Check the format of training data before the model train\n",
    "##########################################################\n",
    "pklpath = '../miBIG/S3_pickle/data-1.pickle'\n",
    "#pklpath = '../miBIG/mibig_train_new3.p'  # size=100\n",
    "#pklpath = '../miBIG/mibig_train_new2.p' # size=60\n",
    "#pklpath = '../miBIG/mibig_train_new.p'  # size=49\n",
    "#pklpath = '../miBIG/mibig_train.p'      # size=60 with format error\n",
    "\n",
    "obj = transformProtein(mapfold = \"./mapping_files\", selectSwiss = 1.0, selectTrembl = 0, maxTaxaPerSample = 3, maxKwPerSample = 5, dropRate = 0.2)\n",
    "with open(pklpath, 'rb') as handle:\n",
    "    train_chunk = pickle.load(handle)\n",
    "\n",
    "    error_uid = []\n",
    "for uid in train_chunk.keys():\n",
    "  try:\n",
    "    sample_arr, existence, thePadIndex = obj.transformSample(train_chunk[uid])\n",
    "    #print(\"loaded UID:\", uid)\n",
    "  except:\n",
    "    error_uid.append(uid)\n",
    "    print(\"Error UID:\", uid)\n",
    "    print(train_chunk[uid])\n",
    "\n",
    "for uid in error_uid:\n",
    "    train_chunk.pop(uid)\n",
    "    print(\"Removed UID:\", uid)\n",
    "    \n",
    "print(\"training data size:\", len(train_chunk))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "train_seq_len = [len(train_chunk[k]['seq'])for k in train_chunk]\n",
    "plt.hist(np.array(train_seq_len), bins=len(train_chunk))\n",
    "plt.xlabel('seq len')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('training data size={}'.format(len(train_chunk)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1618e3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warmup_iteration = 1000,\n",
      "seq_length = 511, \n",
      "batch_size = 4, \n",
      "num_workers = 0, \n",
      "vocab_size = 129407, \n",
      "model_dir = ./checkpoints_cur/finetune_progen_full_demo.pth, \n",
      "save_iter = 1000,\n",
      "pklpath = ../miBIG/S3_pickle/data-1.pickle\n"
     ]
    }
   ],
   "source": [
    "print(f\"warmup_iteration = {args.warmup_iteration},\\\n",
    "\\nseq_length = {seq_length}, \\\n",
    "\\nbatch_size = {args.batch_size}, \\\n",
    "\\nnum_workers = {args.num_workers}, \\\n",
    "\\nvocab_size = {vocab_size}, \\\n",
    "\\nmodel_dir = {args.model_dir}, \\\n",
    "\\nsave_iter = {args.save_iter},\\\n",
    "\\npklpath = {pklpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2157b8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using one unified encoder to represent protein sample with length 129406\n",
      "Using one unified encoder to represent protein sample with length 129406\n",
      "Using one unified encoder to represent protein sample with length 129406\n",
      "begin training...\n",
      "Epoch: 0 ; loss_e: 1.3874166145324707\n",
      "Epoch: 1 ; loss_e: 1.3814938650131225\n",
      "Epoch: 2 ; loss_e: 1.3832782568931579\n",
      "Epoch: 3 ; loss_e: 1.3845192923545837\n",
      "Epoch: 4 ; loss_e: 1.3893987541198731\n",
      "Epoch: 5 ; loss_e: 1.3867882533073426\n",
      "Epoch: 6 ; loss_e: 1.3869417119026184\n",
      "Epoch: 7 ; loss_e: 1.3832877049446106\n",
      "Epoch: 8 ; loss_e: 1.3858445620536803\n",
      "Epoch: 9 ; loss_e: 1.3849984622001648\n",
      "Epoch: 10 ; loss_e: 1.383955334663391\n",
      "Epoch: 11 ; loss_e: 1.3853137402534486\n",
      "Epoch: 12 ; loss_e: 1.3850439429283141\n",
      "Epoch: 13 ; loss_e: 1.3845016827583314\n",
      "Epoch: 14 ; loss_e: 1.3822436647415162\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Train the model\n",
    "##########################################################\n",
    "import time\n",
    "training = Trainer(model=model, warmup_iteration=args.warmup_iteration, seq_length=seq_length,\n",
    "                   batch_size=args.batch_size, num_workers=args.num_workers, vocab_size=vocab_size,\n",
    "                   model_dir = args.model_dir, save_iter=args.save_iter,\n",
    "                   pklpath=pklpath)\n",
    "print('begin training...')\n",
    "start_time = time.time()  # Start time of the training\n",
    "training.train(args.num_epochs)\n",
    "end_time = time.time()  # End time of the training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efa1d8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 4456 seconds\n"
     ]
    }
   ],
   "source": [
    "elapsed_time = end_time - start_time  # Calculate the traiing time\n",
    "print(f\"Elapsed time: {round(elapsed_time)} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c8177",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progen-salesforce",
   "language": "python",
   "name": "progen-salesforce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
