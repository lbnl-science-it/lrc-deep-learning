{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b4d1cca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-02 14:16:02.638838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-06-02 14:16:10.360477: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import sys\n",
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import platform\n",
    "import hashlib\n",
    "import pytorch_transformer\n",
    "import re\n",
    "import argparse\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from transformProtein import transformProtein\n",
    "from ProteinDataset import ProteinDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8334db37",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_py3 = platform.python_version()[0] == '3'\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch code for generating from CTRL')\n",
    "\n",
    "#parser.add_argument('--model_dir', type =str, default='model_v0.pth', help='location of training model checkpoint')\n",
    "#parser.add_argument('--model_path', type=str, default='/home/amadani/ctrl/ckpt/seqlen256_36layers_v0.ckpt/model.ckpt-684000', help='location of model *data* checkpoint to load; this is NOT the directory but rather the model checkpoint')\n",
    "\n",
    "parser.add_argument('--model_dir', type =str, default='./checkpoints_cur/finetune_progen_full.pth', help='location of training model checkpoint')\n",
    "parser.add_argument('--model_path', type=str, default='../checkpoints/pretrain_progen_full.pth', help='location of model *data* checkpoint to load; this is NOT the directory but rather the model checkpoint')\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=313,\n",
    "                                        help='random seed for PyTorch, numpy and PythonHash')\n",
    "parser.add_argument('--sequence_len', type=int, default=511,\n",
    "                                        help='sequence len of model being fine-tuned')\n",
    "parser.add_argument('--num_epochs', type=int, default=10000, help='number of epochs to train for')\n",
    "parser.add_argument('--num_layers', type=int, default=36, help='number of transfomer layers. used for loading checkpoint')\n",
    "parser.add_argument('--batch_size', type=int, default = 4, help='batch size for dataloader')\n",
    "parser.add_argument('--vocab_loc', type=str, default='mapping_files/vocab.txt', help='vocab location')\n",
    "parser.add_argument('--num_workers', type=int, default=0, help='for dataloader')\n",
    "parser.add_argument('--warmup_iteration', type=int, default=1000, help='LR warmup cutoff')\n",
    "parser.add_argument('--save_iter', type=int, default=1000, help='save model checkpoint every X iterations')\n",
    "\n",
    "args = parser.parse_args(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ddac42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args.seed)\n",
    "torch.cuda.manual_seed_all(args.seed)\n",
    "os.environ['PYTHONHASHSEED'] = str(args.seed)\n",
    "np.random.seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19bc0027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----vocab size 129407 ------\n"
     ]
    }
   ],
   "source": [
    "# load the vocabulary from file\n",
    "vocab = open(args.vocab_loc).readlines() if not use_py3 else open(args.vocab_loc, encoding='utf-8').read().split('\\n')[:-1]\n",
    "vocab = list(map(lambda x: x.split(' ')[0], vocab))\n",
    "# length of the vocabulary\n",
    "vocab_size = len(vocab)\n",
    "print('-----vocab size',vocab_size,'------')\n",
    "\n",
    "# define the numericalization map\n",
    "# idx2word maps the numericalized ID to the word\n",
    "# word2idx maps the word to the numericalized ID\n",
    "#word2idx = {u:i for i, u in enumerate(vocab)}\n",
    "#idx2word = np.array(vocab)\n",
    "\n",
    "# sequence length to use for transfomer\n",
    "seq_length = args.sequence_len\n",
    "embedding_dim = 1280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8107b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TiedEmbeddingSoftmax(torch.nn.Module):\n",
    "\n",
    "  def __init__(self, vocab_size=vocab_size, embedding_size=embedding_dim, **kwargs):\n",
    "    super(TiedEmbeddingSoftmax, self).__init__()\n",
    "    self.w = torch.nn.Parameter(torch.normal(0., 1e-2, size=(vocab_size, embedding_size)))\n",
    "    self.b = torch.nn.Parameter(torch.zeros(vocab_size))\n",
    "\n",
    "  def forward(self, inputs, embed=True):\n",
    "    if embed:\n",
    "      return torch.nn.functional.embedding(inputs, self.w)\n",
    "    else:\n",
    "      return torch.tensordot(inputs, self.w.t(), 1) + self.b\n",
    "\n",
    "class CTRLmodel(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super(CTRLmodel,self).__init__()\n",
    "    self.tied_embedding_softmax = TiedEmbeddingSoftmax()\n",
    "    self.encoder = pytorch_transformer.Encoder()\n",
    "\n",
    "  def forward(self, inputs):\n",
    "    x = self.tied_embedding_softmax(inputs, embed = True)\n",
    "    x = self.encoder(x)\n",
    "    x = self.tied_embedding_softmax(x, embed = False)\n",
    "    return x\n",
    "\n",
    "  def loadCheckpoint(self, model_path, num_layers):\n",
    "    #pytorch_model_hash = hashlib.md5(model_path.encode('utf-8')).hexdigest()\n",
    "    pytorch_model_hash = model_path\n",
    "\n",
    "    if os.path.exists(pytorch_model_hash):\n",
    "      print('Found PyTorch checkpoint @', pytorch_model_hash)\n",
    "      print('Loading instead of converting from TensorFlow')\n",
    "      checkpoint = torch.load(pytorch_model_hash)\n",
    "      \n",
    "      #self.tied_embedding_softmax.load_state_dict(checkpoint['softmax'])\n",
    "      #self.encoder.load_state_dict(checkpoint['encoder'])\n",
    "      ## load state dict has KeyError, because checkpoint is ready the state_dict\n",
    "      ## can load checkpoint directly \n",
    "      ## https://discuss.pytorch.org/t/keyerror-state-dict/18220/5\n",
    "      self.load_state_dict(checkpoint)\n",
    "\n",
    "      self.tied_embedding_softmax.to('cuda')\n",
    "      self.encoder.to('cuda')\n",
    "\n",
    "    else:\n",
    "      print('Error: Could not find PyTorch checkpoint')\n",
    "      sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cafe8e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model initialized\n"
     ]
    }
   ],
   "source": [
    "# initialize ctrl object\n",
    "model = CTRLmodel()\n",
    "print('model initialized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a6e25ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found PyTorch checkpoint @ ../checkpoints/pretrain_progen_full.pth\n",
      "Loading instead of converting from TensorFlow\n",
      "previous checkpoint loaded\n"
     ]
    }
   ],
   "source": [
    "# load checkpoint with args.model_path\n",
    "model.loadCheckpoint(model_path=args.model_path, num_layers = args.num_layers)\n",
    "print('previous checkpoint loaded')\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2e2e4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all weights except embedding\n",
    "for p in model.parameters():\n",
    "    p.requires_grad=False\n",
    "model.tied_embedding_softmax.w.requires_grad=True\n",
    "model.tied_embedding_softmax.b.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77700dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, warmup_iteration, seq_length, batch_size, num_workers, vocab_size, model_dir, save_iter):\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.vocab_size = vocab_size\n",
    "        self.model_dir = model_dir\n",
    "        self.save_iter = save_iter\n",
    "        self.firstAAidx = self.vocab_size - 26 # Assuming that the pad token is the last token and AAs are at the end\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters()) #lr, betas\n",
    "        lambdafn = lambda iteration: min(iteration/(warmup_iteration*1.0),1.0)\n",
    "        self.scheduler = torch.optim.lr_scheduler.LambdaLR(self.optimizer, lambdafn)\n",
    "        \n",
    "        self.criterion = torch.nn.CrossEntropyLoss(ignore_index=self.vocab_size-1, reduction='none')\n",
    "        \n",
    "        self.transformFull = transformProtein(maxSampleLength = seq_length+1, \n",
    "                                              selectSwiss = 1.0, selectTrembl = 0, \n",
    "                                              maxTaxaPerSample = 3, maxKwPerSample = 5, dropRate = 0.2)\n",
    "        self.transformPartial = transformProtein(maxSampleLength = seq_length+1,   \n",
    "                                                 selectSwiss = 1.0, selectTrembl = 0,\n",
    "                                                 maxTaxaPerSample = 3, maxKwPerSample = 5, dropRate = 0.2)\n",
    "        self.transformNone = transformProtein(maxSampleLength = seq_length+1,   \n",
    "                                              selectSwiss = 1.0, selectTrembl = 0,\n",
    "                                              maxTaxaPerSample = 3, maxKwPerSample = 5, dropRate = 0.2)\n",
    "        \n",
    "        self.writer = SummaryWriter()\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        self.model.train()\n",
    "\n",
    "        iter_num = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            loss_e = 0.0\n",
    "            num_e = 0\n",
    "\n",
    "            for chunknum in range(1):\n",
    "                pklpath = '../miBIG/mibig_train_new.p'\n",
    "                chunk_dataset = ProteinDataset(pklpath, firstAAidx = self.firstAAidx, transformFull = self.transformFull, \n",
    "                                               transformPartial = self.transformPartial, transformNone = self.transformNone)\n",
    "                dataloader = DataLoader(chunk_dataset, shuffle = True, batch_size = self.batch_size,\n",
    "                                        num_workers = self.num_workers, pin_memory = False) #TODO pinmem?\n",
    "                \n",
    "                for i, (sample, labels, existence, padIndex, begAAindex) in enumerate(dataloader):\n",
    "                    self.optimizer.zero_grad()\n",
    "                    sample, labels, existence, padIndex = sample.cuda(), labels.cuda(), existence.cuda(), padIndex.cuda()\n",
    "                    output = self.model(sample)\n",
    "                    #pdb.set_trace()\n",
    "                    loss = self.criterion(output.permute(0,2,1), labels)\n",
    "                    loss = torch.mean((torch.sum(loss,dim=1)/padIndex)*existence) #pad masking, loss weighting\n",
    "                    loss.backward()\n",
    "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.25)\n",
    "                    self.optimizer.step()\n",
    "                    self.scheduler.step()\n",
    "                    loss_e += loss.item()\n",
    "                    num_e += sample.shape[0]\n",
    "                    iter_num += 1\n",
    "                    self.writer.add_scalar('Loss_iteration',loss.item(),iter_num)\n",
    "\n",
    "                    if (iter_num+1)%self.save_iter==0:\n",
    "                        torch.save({'epoch': epoch, 'chunknum': chunknum, 'iteration':iter_num,\n",
    "                                    'model_state_dict': self.model.state_dict(),\n",
    "                                    'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "                                    'loss': loss,\n",
    "                                   }, self.model_dir)\n",
    "                loss_e/=num_e\n",
    "            print(\"Epoch: {0} ; loss_e: {1}\".format(epoch, loss_e))\n",
    "            self.writer.add_scalar('Loss_epoch',loss_e, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e79e4d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using one unified encoder to represent protein sample with length 129406\n",
      "loaded UID: BGC0001135\n",
      "loaded UID: BGC0001348\n",
      "loaded UID: BGC0002135\n",
      "loaded UID: BGC0001185\n",
      "loaded UID: BGC0000431\n",
      "loaded UID: BGC0000114\n",
      "loaded UID: BGC0001873\n",
      "loaded UID: BGC0001133\n",
      "loaded UID: BGC0002092\n",
      "loaded UID: BGC0001462\n",
      "loaded UID: BGC0001164\n",
      "loaded UID: BGC0000175\n",
      "loaded UID: BGC0001875\n",
      "loaded UID: BGC0000302\n",
      "loaded UID: BGC0002086\n",
      "loaded UID: BGC0001437\n",
      "loaded UID: BGC0000290\n",
      "loaded UID: BGC0000386\n",
      "loaded UID: BGC0001163\n",
      "loaded UID: BGC0001838\n",
      "loaded UID: BGC0000171\n",
      "loaded UID: BGC0002078\n",
      "loaded UID: BGC0002071\n",
      "loaded UID: BGC0001338\n",
      "loaded UID: BGC0000427\n",
      "loaded UID: BGC0002091\n",
      "loaded UID: BGC0000208\n",
      "loaded UID: BGC0000399\n",
      "loaded UID: BGC0001844\n",
      "loaded UID: BGC0000306\n",
      "loaded UID: BGC0001459\n",
      "loaded UID: BGC0001460\n",
      "loaded UID: BGC0001283\n",
      "loaded UID: BGC0000446\n",
      "loaded UID: BGC0001118\n",
      "loaded UID: BGC0002051\n",
      "loaded UID: BGC0000165\n",
      "loaded UID: BGC0000357\n",
      "loaded UID: BGC0002137\n",
      "loaded UID: BGC0002081\n",
      "loaded UID: BGC0001831\n",
      "loaded UID: BGC0000442\n",
      "loaded UID: BGC0001160\n",
      "loaded UID: BGC0001446\n",
      "loaded UID: BGC0001123\n",
      "loaded UID: BGC0001461\n",
      "loaded UID: BGC0001132\n",
      "loaded UID: BGC0000416\n",
      "loaded UID: BGC0001872\n",
      "loaded UID: BGC0001629\n",
      "loaded UID: BGC0000818\n",
      "loaded UID: BGC0000384\n",
      "loaded UID: BGC0001442\n",
      "loaded UID: BGC0001833\n",
      "loaded UID: BGC0000319\n",
      "loaded UID: BGC0002079\n",
      "loaded UID: BGC0000333\n",
      "loaded UID: BGC0001836\n",
      "loaded UID: BGC0001877\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Check the format of training data before the model train\n",
    "##########################################################\n",
    "pklpath = '../miBIG/mibig_train_new.p'\n",
    "obj = transformProtein(mapfold = \"./mapping_files\", selectSwiss = 1.0, selectTrembl = 0, maxTaxaPerSample = 3, maxKwPerSample = 5, dropRate = 0.2)\n",
    "with open(pklpath, 'rb') as handle:\n",
    "    train_chunk = pickle.load(handle)\n",
    "for uid in train_chunk.keys():\n",
    "  try:\n",
    "    sample_arr, existence, thePadIndex = obj.transformSample(train_chunk[uid])\n",
    "    print(\"loaded UID:\", uid)\n",
    "  except:\n",
    "    print(\"Error UID:\", uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47abf96c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using one unified encoder to represent protein sample with length 129406\n",
      "Using one unified encoder to represent protein sample with length 129406\n",
      "Using one unified encoder to represent protein sample with length 129406\n",
      "begin training...\n",
      "Epoch: 0 ; loss_e: 1.4126384217860335\n",
      "Epoch: 1 ; loss_e: 1.3944427684202032\n",
      "Epoch: 2 ; loss_e: 1.4026997048976058\n",
      "Epoch: 3 ; loss_e: 1.4236019263833255\n",
      "Epoch: 4 ; loss_e: 1.395690829066907\n",
      "Epoch: 5 ; loss_e: 1.385220640796726\n",
      "Epoch: 6 ; loss_e: 1.3784518565161754\n",
      "Epoch: 7 ; loss_e: 1.3773530054900607\n",
      "Epoch: 8 ; loss_e: 1.3620156433622717\n",
      "Epoch: 9 ; loss_e: 1.3684471340502722\n",
      "Epoch: 10 ; loss_e: 1.3602669117814403\n",
      "Epoch: 11 ; loss_e: 1.360598693459721\n",
      "Epoch: 12 ; loss_e: 1.3541271726963884\n",
      "Epoch: 13 ; loss_e: 1.3477891501733812\n",
      "Epoch: 14 ; loss_e: 1.3338587001218634\n",
      "Epoch: 15 ; loss_e: 1.3282211594662423\n",
      "Epoch: 16 ; loss_e: 1.3225327265464653\n",
      "Epoch: 17 ; loss_e: 1.309960882542497\n",
      "Epoch: 18 ; loss_e: 1.296852814949165\n",
      "Epoch: 19 ; loss_e: 1.3004135358131539\n",
      "Epoch: 20 ; loss_e: 1.2902553283562095\n",
      "Epoch: 21 ; loss_e: 1.2827795077178439\n",
      "Epoch: 22 ; loss_e: 1.2558070926342981\n",
      "Epoch: 23 ; loss_e: 1.2525144997289626\n",
      "Epoch: 24 ; loss_e: 1.2560920957791604\n",
      "Epoch: 25 ; loss_e: 1.23730728181742\n",
      "Epoch: 26 ; loss_e: 1.2317990044416007\n",
      "Epoch: 27 ; loss_e: 1.2292481923507432\n",
      "Epoch: 28 ; loss_e: 1.216019541530286\n",
      "Epoch: 29 ; loss_e: 1.197290105334783\n",
      "Epoch: 30 ; loss_e: 1.1855241322921495\n",
      "Epoch: 31 ; loss_e: 1.1835297002630718\n",
      "Epoch: 32 ; loss_e: 1.1781167903188932\n",
      "Epoch: 33 ; loss_e: 1.168779437824831\n",
      "Epoch: 34 ; loss_e: 1.1571570978326313\n",
      "Epoch: 35 ; loss_e: 1.1402339531203447\n",
      "Epoch: 36 ; loss_e: 1.133923837694071\n",
      "Epoch: 37 ; loss_e: 1.1305986178123344\n",
      "Epoch: 38 ; loss_e: 1.1184319803270244\n",
      "Epoch: 39 ; loss_e: 1.109556747695147\n",
      "Epoch: 40 ; loss_e: 1.1051616022142314\n",
      "Epoch: 41 ; loss_e: 1.097275216700667\n",
      "Epoch: 42 ; loss_e: 1.0783573894177454\n",
      "Epoch: 43 ; loss_e: 1.0711989160311424\n",
      "Epoch: 44 ; loss_e: 1.0626872515274306\n",
      "Epoch: 45 ; loss_e: 1.0625241085634394\n",
      "Epoch: 46 ; loss_e: 1.0438721058732372\n",
      "Epoch: 47 ; loss_e: 1.040767920219292\n",
      "Epoch: 48 ; loss_e: 1.0367608757342321\n",
      "Epoch: 49 ; loss_e: 1.0167803239014188\n",
      "Epoch: 50 ; loss_e: 1.0257849774118197\n",
      "Epoch: 51 ; loss_e: 1.011094966177213\n",
      "Epoch: 52 ; loss_e: 0.9964718131695763\n",
      "Epoch: 53 ; loss_e: 0.9866220870260465\n",
      "Epoch: 54 ; loss_e: 0.9827391656778627\n",
      "Epoch: 55 ; loss_e: 0.9733733201431016\n",
      "Epoch: 56 ; loss_e: 0.9718369104094424\n",
      "Epoch: 57 ; loss_e: 0.959640668610395\n",
      "Epoch: 58 ; loss_e: 0.9530257451332221\n",
      "Epoch: 59 ; loss_e: 0.9525057218842587\n",
      "Epoch: 60 ; loss_e: 0.9450397814734507\n",
      "Epoch: 61 ; loss_e: 0.9315360238996603\n",
      "Epoch: 62 ; loss_e: 0.9340199777635477\n",
      "Epoch: 63 ; loss_e: 0.9275557711973028\n",
      "Epoch: 64 ; loss_e: 0.926194732472048\n",
      "Epoch: 65 ; loss_e: 0.9117209062737933\n",
      "Epoch: 66 ; loss_e: 0.9124032683291677\n",
      "Epoch: 67 ; loss_e: 0.9142045611042088\n",
      "Epoch: 68 ; loss_e: 0.8993798554953882\n",
      "Epoch: 69 ; loss_e: 0.8898309085328701\n",
      "Epoch: 70 ; loss_e: 0.8847002457764189\n",
      "Epoch: 71 ; loss_e: 0.8864642280643269\n",
      "Epoch: 72 ; loss_e: 0.8673150701037908\n",
      "Epoch: 73 ; loss_e: 0.8670385894128831\n",
      "Epoch: 74 ; loss_e: 0.8855128490318687\n",
      "Epoch: 75 ; loss_e: 0.8683739193415237\n",
      "Epoch: 76 ; loss_e: 0.8731555979130632\n",
      "Epoch: 77 ; loss_e: 0.8603357581769006\n",
      "Epoch: 78 ; loss_e: 0.8553587703381554\n",
      "Epoch: 79 ; loss_e: 0.8553065889972752\n",
      "Epoch: 80 ; loss_e: 0.8739335092447572\n",
      "Epoch: 81 ; loss_e: 0.8559701119439077\n",
      "Epoch: 82 ; loss_e: 0.8395769878969355\n",
      "Epoch: 83 ; loss_e: 0.8429983227939929\n",
      "Epoch: 84 ; loss_e: 0.8157109931363897\n",
      "Epoch: 85 ; loss_e: 0.8292097560429977\n",
      "Epoch: 86 ; loss_e: 0.8187101937956729\n",
      "Epoch: 87 ; loss_e: 0.8301353979918916\n",
      "Epoch: 88 ; loss_e: 0.8105664536104364\n",
      "Epoch: 89 ; loss_e: 0.8080818208597474\n",
      "Epoch: 90 ; loss_e: 0.8184385622962046\n",
      "Epoch: 91 ; loss_e: 0.8011648493298029\n",
      "Epoch: 92 ; loss_e: 0.8327740046937587\n",
      "Epoch: 93 ; loss_e: 0.8011606386152365\n",
      "Epoch: 94 ; loss_e: 0.8011827953791214\n",
      "Epoch: 95 ; loss_e: 0.7993774090783071\n",
      "Epoch: 96 ; loss_e: 0.805411047854666\n",
      "Epoch: 97 ; loss_e: 0.7911980232949984\n",
      "Epoch: 98 ; loss_e: 0.797299255759029\n",
      "Epoch: 99 ; loss_e: 0.7897651437985695\n",
      "Epoch: 100 ; loss_e: 0.7907485517404848\n",
      "Epoch: 101 ; loss_e: 0.7875971551668846\n",
      "Epoch: 102 ; loss_e: 0.7841640448166152\n",
      "Epoch: 103 ; loss_e: 0.7787592289811474\n",
      "Epoch: 104 ; loss_e: 0.776513495687711\n",
      "Epoch: 105 ; loss_e: 0.7835593789310779\n",
      "Epoch: 106 ; loss_e: 0.7787242743928554\n",
      "Epoch: 107 ; loss_e: 0.7902612039598368\n",
      "Epoch: 108 ; loss_e: 0.7761507963730117\n",
      "Epoch: 109 ; loss_e: 0.7990146733946719\n",
      "Epoch: 110 ; loss_e: 0.7835986371767723\n",
      "Epoch: 111 ; loss_e: 0.7707330331964007\n",
      "Epoch: 112 ; loss_e: 0.763032727322336\n",
      "Epoch: 113 ; loss_e: 0.7618587784847971\n",
      "Epoch: 114 ; loss_e: 0.7493834051035219\n",
      "Epoch: 115 ; loss_e: 0.7655053502422268\n",
      "Epoch: 116 ; loss_e: 0.7625363196356821\n",
      "Epoch: 117 ; loss_e: 0.7528051440998659\n",
      "Epoch: 118 ; loss_e: 0.7578772932796155\n",
      "Epoch: 119 ; loss_e: 0.742632312289739\n",
      "Epoch: 120 ; loss_e: 0.7496970952567408\n",
      "Epoch: 121 ; loss_e: 0.7721342959646451\n",
      "Epoch: 122 ; loss_e: 0.7663645259404587\n",
      "Epoch: 123 ; loss_e: 0.7471063015824657\n",
      "Epoch: 124 ; loss_e: 0.7369274729389256\n",
      "Epoch: 125 ; loss_e: 0.7339742991883876\n",
      "Epoch: 126 ; loss_e: 0.7401128987134513\n",
      "Epoch: 127 ; loss_e: 0.7483766321408547\n",
      "Epoch: 128 ; loss_e: 0.7492682408478301\n",
      "Epoch: 129 ; loss_e: 0.7424345137709278\n",
      "Epoch: 130 ; loss_e: 0.726988355992204\n",
      "Epoch: 131 ; loss_e: 0.7390625113147801\n",
      "Epoch: 132 ; loss_e: 0.733852822901839\n",
      "Epoch: 133 ; loss_e: 0.7205184718309823\n",
      "Epoch: 134 ; loss_e: 0.7286968594890529\n",
      "Epoch: 135 ; loss_e: 0.734810275546575\n",
      "Epoch: 136 ; loss_e: 0.7329392311936718\n",
      "Epoch: 137 ; loss_e: 0.7300369901172186\n",
      "Epoch: 138 ; loss_e: 0.7186224218142234\n",
      "Epoch: 139 ; loss_e: 0.7315737837452\n",
      "Epoch: 140 ; loss_e: 0.7176321239794715\n",
      "Epoch: 141 ; loss_e: 0.7311122336630094\n",
      "Epoch: 142 ; loss_e: 0.7201836432440806\n",
      "Epoch: 143 ; loss_e: 0.7123913684133756\n",
      "Epoch: 144 ; loss_e: 0.7212238756276793\n",
      "Epoch: 145 ; loss_e: 0.714675616409819\n",
      "Epoch: 146 ; loss_e: 0.7229537842637401\n",
      "Epoch: 147 ; loss_e: 0.7199739763292216\n",
      "Epoch: 148 ; loss_e: 0.7221366712602518\n",
      "Epoch: 149 ; loss_e: 0.7018865973262464\n",
      "Epoch: 150 ; loss_e: 0.7001376354088218\n",
      "Epoch: 151 ; loss_e: 0.7019269021890931\n",
      "Epoch: 152 ; loss_e: 0.7113430984949661\n",
      "Epoch: 153 ; loss_e: 0.6946511147385936\n",
      "Epoch: 154 ; loss_e: 0.7048030990665242\n",
      "Epoch: 155 ; loss_e: 0.7036225270416777\n",
      "Epoch: 156 ; loss_e: 0.690547470319069\n",
      "Epoch: 157 ; loss_e: 0.6969171055292679\n",
      "Epoch: 158 ; loss_e: 0.6970697095838644\n",
      "Epoch: 159 ; loss_e: 0.6968515969939151\n",
      "Epoch: 160 ; loss_e: 0.6999935093572585\n",
      "Epoch: 161 ; loss_e: 0.6959055237850901\n",
      "Epoch: 162 ; loss_e: 0.704991671998622\n",
      "Epoch: 163 ; loss_e: 0.7027378324734963\n",
      "Epoch: 164 ; loss_e: 0.700694973185911\n",
      "Epoch: 165 ; loss_e: 0.7112004352828204\n",
      "Epoch: 166 ; loss_e: 0.7296823889522229\n",
      "Epoch: 167 ; loss_e: 0.6866276223780745\n",
      "Epoch: 168 ; loss_e: 0.7036129620115635\n",
      "Epoch: 169 ; loss_e: 0.6966322599831274\n",
      "Epoch: 170 ; loss_e: 0.6912863577826548\n",
      "Epoch: 171 ; loss_e: 0.7056651802386268\n",
      "Epoch: 172 ; loss_e: 0.6945676843998796\n",
      "Epoch: 173 ; loss_e: 0.7015471943354202\n",
      "Epoch: 174 ; loss_e: 0.6965663028975665\n",
      "Epoch: 175 ; loss_e: 0.6868762808330988\n",
      "Epoch: 176 ; loss_e: 0.6955827171519652\n",
      "Epoch: 177 ; loss_e: 0.6794375484272585\n",
      "Epoch: 178 ; loss_e: 0.6825547420372398\n",
      "Epoch: 179 ; loss_e: 0.69434429831424\n",
      "Epoch: 180 ; loss_e: 0.6834040900408211\n",
      "Epoch: 181 ; loss_e: 0.6874387587531138\n",
      "Epoch: 182 ; loss_e: 0.6759105617717162\n",
      "Epoch: 183 ; loss_e: 0.6952148736533472\n",
      "Epoch: 184 ; loss_e: 0.6892285831904007\n",
      "Epoch: 185 ; loss_e: 0.6792104123002392\n",
      "Epoch: 186 ; loss_e: 0.6879849716768427\n",
      "Epoch: 187 ; loss_e: 0.6831176078925698\n",
      "Epoch: 188 ; loss_e: 0.6929060281333277\n",
      "Epoch: 189 ; loss_e: 0.6752197136313228\n",
      "Epoch: 190 ; loss_e: 0.6975331346867448\n",
      "Epoch: 191 ; loss_e: 0.6719518031104136\n",
      "Epoch: 192 ; loss_e: 0.6763143822298212\n",
      "Epoch: 193 ; loss_e: 0.6760238873756538\n",
      "Epoch: 194 ; loss_e: 0.6693902096505893\n",
      "Epoch: 195 ; loss_e: 0.6909992411985235\n",
      "Epoch: 196 ; loss_e: 0.6720107046224303\n",
      "Epoch: 197 ; loss_e: 0.6832807346925898\n",
      "Epoch: 198 ; loss_e: 0.6751027794207557\n",
      "Epoch: 199 ; loss_e: 0.6772633043386168\n",
      "Epoch: 200 ; loss_e: 0.6820025524850619\n",
      "Epoch: 201 ; loss_e: 0.6888375686386884\n",
      "Epoch: 202 ; loss_e: 0.6725342758631302\n",
      "Epoch: 203 ; loss_e: 0.6893617783562612\n",
      "Epoch: 204 ; loss_e: 0.674545635611324\n",
      "Epoch: 205 ; loss_e: 0.6664342637789451\n",
      "Epoch: 206 ; loss_e: 0.6660910258858891\n",
      "Epoch: 207 ; loss_e: 0.6603348497617043\n",
      "Epoch: 208 ; loss_e: 0.6838065042334088\n",
      "Epoch: 209 ; loss_e: 0.6604925980002193\n",
      "Epoch: 210 ; loss_e: 0.6638712600126104\n",
      "Epoch: 211 ; loss_e: 0.658268116288266\n",
      "Epoch: 212 ; loss_e: 0.6719233828075861\n",
      "Epoch: 213 ; loss_e: 0.6695502652960309\n",
      "Epoch: 214 ; loss_e: 0.6691315699431856\n",
      "Epoch: 215 ; loss_e: 0.6787130913491977\n",
      "Epoch: 216 ; loss_e: 0.667690774141732\n",
      "Epoch: 217 ; loss_e: 0.6628889310157905\n",
      "Epoch: 218 ; loss_e: 0.6582670009742349\n",
      "Epoch: 219 ; loss_e: 0.6604334701926021\n",
      "Epoch: 220 ; loss_e: 0.6550589739266088\n",
      "Epoch: 221 ; loss_e: 0.6630691673796055\n",
      "Epoch: 222 ; loss_e: 0.6585076097714699\n",
      "Epoch: 223 ; loss_e: 0.6480200694779218\n",
      "Epoch: 224 ; loss_e: 0.6566433421636032\n",
      "Epoch: 225 ; loss_e: 0.6511924994193902\n",
      "Epoch: 226 ; loss_e: 0.6464001364627127\n",
      "Epoch: 227 ; loss_e: 0.6658769987397275\n",
      "Epoch: 228 ; loss_e: 0.6552095978947009\n",
      "Epoch: 229 ; loss_e: 0.6674128548573639\n",
      "Epoch: 230 ; loss_e: 0.6653237221604686\n",
      "Epoch: 231 ; loss_e: 0.6565176511214952\n",
      "Epoch: 232 ; loss_e: 0.6610722582219011\n",
      "Epoch: 233 ; loss_e: 0.6504609019069348\n",
      "Epoch: 234 ; loss_e: 0.6742095219886909\n",
      "Epoch: 235 ; loss_e: 0.6605536816483837\n",
      "Epoch: 236 ; loss_e: 0.6414098416344595\n",
      "Epoch: 237 ; loss_e: 0.6436650631791454\n",
      "Epoch: 238 ; loss_e: 0.6429205021615756\n",
      "Epoch: 239 ; loss_e: 0.6620901924068645\n",
      "Epoch: 240 ; loss_e: 0.6423705836473885\n",
      "Epoch: 241 ; loss_e: 0.6504403938681392\n",
      "Epoch: 242 ; loss_e: 0.6592568947097003\n",
      "Epoch: 243 ; loss_e: 0.6468703665975797\n",
      "Epoch: 244 ; loss_e: 0.6622162592613091\n",
      "Epoch: 245 ; loss_e: 0.6467591948428396\n",
      "Epoch: 246 ; loss_e: 0.6554883940745209\n",
      "Epoch: 247 ; loss_e: 0.6517107769594355\n",
      "Epoch: 248 ; loss_e: 0.64633788496761\n",
      "Epoch: 249 ; loss_e: 0.6528816344374317\n",
      "Epoch: 250 ; loss_e: 0.6509601786985235\n",
      "Epoch: 251 ; loss_e: 0.6460572703410004\n",
      "Epoch: 252 ; loss_e: 0.6469665947607008\n",
      "Epoch: 253 ; loss_e: 0.6467637712672606\n",
      "Epoch: 254 ; loss_e: 0.6527177762177031\n",
      "Epoch: 255 ; loss_e: 0.651690050707025\n",
      "Epoch: 256 ; loss_e: 0.670483176991091\n",
      "Epoch: 257 ; loss_e: 0.6627372765945176\n",
      "Epoch: 258 ; loss_e: 0.6686727596541583\n",
      "Epoch: 259 ; loss_e: 0.6499793125411212\n",
      "Epoch: 260 ; loss_e: 0.6430066116785599\n",
      "Epoch: 261 ; loss_e: 0.6337630465879278\n",
      "Epoch: 262 ; loss_e: 0.6529815237400896\n",
      "Epoch: 263 ; loss_e: 0.642955687086461\n",
      "Epoch: 264 ; loss_e: 0.6375689748990334\n",
      "Epoch: 265 ; loss_e: 0.6484419289281813\n",
      "Epoch: 266 ; loss_e: 0.629076361656189\n",
      "Epoch: 267 ; loss_e: 0.6413527908971755\n",
      "Epoch: 268 ; loss_e: 0.6464318016828117\n",
      "Epoch: 269 ; loss_e: 0.635808839636334\n",
      "Epoch: 270 ; loss_e: 0.6365873409529864\n",
      "Epoch: 271 ; loss_e: 0.6423820843130855\n",
      "Epoch: 272 ; loss_e: 0.6314851187043271\n",
      "Epoch: 273 ; loss_e: 0.6568485316583665\n",
      "Epoch: 274 ; loss_e: 0.632557190070718\n",
      "Epoch: 275 ; loss_e: 0.6429669493335789\n",
      "Epoch: 276 ; loss_e: 0.6311347322948908\n",
      "Epoch: 277 ; loss_e: 0.644285569756718\n",
      "Epoch: 278 ; loss_e: 0.6463305404630758\n",
      "Epoch: 279 ; loss_e: 0.6449156252004332\n",
      "Epoch: 280 ; loss_e: 0.6352720220210188\n",
      "Epoch: 281 ; loss_e: 0.652626134581485\n",
      "Epoch: 282 ; loss_e: 0.6410782175549006\n",
      "Epoch: 283 ; loss_e: 0.6530112775705629\n",
      "Epoch: 284 ; loss_e: 0.651278653387296\n",
      "Epoch: 285 ; loss_e: 0.6556598816887808\n",
      "Epoch: 286 ; loss_e: 0.6466867721686929\n",
      "Epoch: 287 ; loss_e: 0.6258575754650568\n",
      "Epoch: 288 ; loss_e: 0.6399313231646004\n",
      "Epoch: 289 ; loss_e: 0.6361700862140979\n",
      "Epoch: 290 ; loss_e: 0.648107363005816\n",
      "Epoch: 291 ; loss_e: 0.6270849583512645\n",
      "Epoch: 292 ; loss_e: 0.6478758464425297\n",
      "Epoch: 293 ; loss_e: 0.6297900676727295\n",
      "Epoch: 294 ; loss_e: 0.6371564299373303\n",
      "Epoch: 295 ; loss_e: 0.6419606047161555\n",
      "Epoch: 296 ; loss_e: 0.6473396875090518\n",
      "Epoch: 297 ; loss_e: 0.628623683573836\n",
      "Epoch: 298 ; loss_e: 0.638848821995622\n",
      "Epoch: 299 ; loss_e: 0.6254361766879841\n",
      "Epoch: 300 ; loss_e: 0.6477593001672777\n",
      "Epoch: 301 ; loss_e: 0.6281707852573718\n",
      "Epoch: 302 ; loss_e: 0.6284386586334746\n",
      "Epoch: 303 ; loss_e: 0.6381835169711355\n",
      "Epoch: 304 ; loss_e: 0.6244247404195494\n",
      "Epoch: 305 ; loss_e: 0.6331272973852643\n",
      "Epoch: 306 ; loss_e: 0.6419281312974833\n",
      "Epoch: 307 ; loss_e: 0.6274431115489895\n",
      "Epoch: 308 ; loss_e: 0.6439690104985641\n",
      "Epoch: 309 ; loss_e: 0.6396609120449778\n",
      "Epoch: 310 ; loss_e: 0.6371316101591465\n",
      "Epoch: 311 ; loss_e: 0.6421316478212001\n",
      "Epoch: 312 ; loss_e: 0.6258238412566104\n",
      "Epoch: 313 ; loss_e: 0.6318774789066638\n",
      "Epoch: 314 ; loss_e: 0.6314942432662188\n",
      "Epoch: 315 ; loss_e: 0.6175829394389007\n",
      "Epoch: 316 ; loss_e: 0.6234100693363255\n",
      "Epoch: 317 ; loss_e: 0.6424199726621983\n",
      "Epoch: 318 ; loss_e: 0.6178982702352233\n",
      "Epoch: 319 ; loss_e: 0.6179475461022329\n",
      "Epoch: 320 ; loss_e: 0.653059417918577\n",
      "Epoch: 321 ; loss_e: 0.6461656861386057\n",
      "Epoch: 322 ; loss_e: 0.6342861207865053\n",
      "Epoch: 323 ; loss_e: 0.625610020201085\n",
      "Epoch: 324 ; loss_e: 0.629672870797626\n",
      "Epoch: 325 ; loss_e: 0.6398446357856362\n",
      "Epoch: 326 ; loss_e: 0.6409272157539756\n",
      "Epoch: 327 ; loss_e: 0.630959153175354\n",
      "Epoch: 328 ; loss_e: 0.6350155341423164\n",
      "Epoch: 329 ; loss_e: 0.6289742073770297\n",
      "Epoch: 330 ; loss_e: 0.6195261539038965\n",
      "Epoch: 331 ; loss_e: 0.6245666216995757\n",
      "Epoch: 332 ; loss_e: 0.6241165924880464\n",
      "Epoch: 333 ; loss_e: 0.634654542147103\n",
      "Epoch: 334 ; loss_e: 0.6200952449087369\n",
      "Epoch: 335 ; loss_e: 0.628692776469861\n",
      "Epoch: 336 ; loss_e: 0.6281922227245266\n",
      "Epoch: 337 ; loss_e: 0.6295968071889069\n",
      "Epoch: 338 ; loss_e: 0.6222772113347458\n",
      "Epoch: 339 ; loss_e: 0.6096113738367113\n",
      "Epoch: 340 ; loss_e: 0.6081165499606375\n",
      "Epoch: 341 ; loss_e: 0.6386491242101637\n",
      "Epoch: 342 ; loss_e: 0.6192697104761156\n",
      "Epoch: 343 ; loss_e: 0.612383307036707\n",
      "Epoch: 344 ; loss_e: 0.6245041600728439\n",
      "Epoch: 345 ; loss_e: 0.6244507745160894\n",
      "Epoch: 346 ; loss_e: 0.6154562154058683\n",
      "Epoch: 347 ; loss_e: 0.6161086983599905\n",
      "Epoch: 348 ; loss_e: 0.618485026440378\n",
      "Epoch: 349 ; loss_e: 0.6279173503487797\n",
      "Epoch: 350 ; loss_e: 0.6188949851666466\n",
      "Epoch: 351 ; loss_e: 0.6289995928942147\n",
      "Epoch: 352 ; loss_e: 0.6323567022711544\n",
      "Epoch: 353 ; loss_e: 0.6111680430881048\n",
      "Epoch: 354 ; loss_e: 0.6328671079570964\n",
      "Epoch: 355 ; loss_e: 0.6266355070017152\n",
      "Epoch: 356 ; loss_e: 0.6163990901688398\n",
      "Epoch: 357 ; loss_e: 0.6224804409479691\n",
      "Epoch: 358 ; loss_e: 0.6239040463657702\n",
      "Epoch: 359 ; loss_e: 0.61401560346959\n",
      "Epoch: 360 ; loss_e: 0.6273098699117111\n",
      "Epoch: 361 ; loss_e: 0.616816413604607\n",
      "Epoch: 362 ; loss_e: 0.6336704957283149\n",
      "Epoch: 363 ; loss_e: 0.6043936559709452\n",
      "Epoch: 364 ; loss_e: 0.6164400981644452\n",
      "Epoch: 365 ; loss_e: 0.6333104190179857\n",
      "Epoch: 366 ; loss_e: 0.6150978338920464\n",
      "Epoch: 367 ; loss_e: 0.62034558643729\n",
      "Epoch: 368 ; loss_e: 0.6165574647612491\n",
      "Epoch: 369 ; loss_e: 0.6045890117095689\n",
      "Epoch: 370 ; loss_e: 0.6343739194385076\n",
      "Epoch: 371 ; loss_e: 0.6136080652980481\n",
      "Epoch: 372 ; loss_e: 0.6084313291614338\n",
      "Epoch: 373 ; loss_e: 0.6169565451347222\n",
      "Epoch: 374 ; loss_e: 0.6164496672355523\n",
      "Epoch: 375 ; loss_e: 0.6103185516292766\n",
      "Epoch: 376 ; loss_e: 0.6183700682753224\n",
      "Epoch: 377 ; loss_e: 0.6123851820573969\n",
      "Epoch: 378 ; loss_e: 0.6203920477527683\n",
      "Epoch: 379 ; loss_e: 0.6120043730331679\n",
      "Epoch: 380 ; loss_e: 0.6198721720000445\n",
      "Epoch: 381 ; loss_e: 0.6172129663370424\n",
      "Epoch: 382 ; loss_e: 0.6260980973809452\n",
      "Epoch: 383 ; loss_e: 0.6241100016286818\n",
      "Epoch: 384 ; loss_e: 0.593811758493973\n",
      "Epoch: 385 ; loss_e: 0.6096486782623549\n",
      "Epoch: 386 ; loss_e: 0.6153522426799193\n",
      "Epoch: 387 ; loss_e: 0.6436693668365479\n",
      "Epoch: 388 ; loss_e: 0.6057001796819396\n",
      "Epoch: 389 ; loss_e: 0.6227945372209711\n",
      "Epoch: 390 ; loss_e: 0.6225751456567796\n",
      "Epoch: 391 ; loss_e: 0.6105338941186161\n",
      "Epoch: 392 ; loss_e: 0.60398337800624\n",
      "Epoch: 393 ; loss_e: 0.6116962170196791\n",
      "Epoch: 394 ; loss_e: 0.6218811192754972\n",
      "Epoch: 395 ; loss_e: 0.619195216793125\n",
      "Epoch: 396 ; loss_e: 0.6021872738660392\n",
      "Epoch: 397 ; loss_e: 0.608987733469171\n",
      "Epoch: 398 ; loss_e: 0.6068320132918277\n",
      "Epoch: 399 ; loss_e: 0.6245775586467678\n",
      "Epoch: 400 ; loss_e: 0.619110364024922\n",
      "Epoch: 401 ; loss_e: 0.5903527170924817\n",
      "Epoch: 402 ; loss_e: 0.601449275420884\n",
      "Epoch: 403 ; loss_e: 0.6130912101874917\n",
      "Epoch: 404 ; loss_e: 0.6087770199371596\n",
      "Epoch: 405 ; loss_e: 0.6144357374158956\n",
      "Epoch: 406 ; loss_e: 0.6129522869142435\n",
      "Epoch: 407 ; loss_e: 0.644881434359793\n",
      "Epoch: 408 ; loss_e: 0.6121942350419901\n",
      "Epoch: 409 ; loss_e: 0.6052809630410146\n",
      "Epoch: 410 ; loss_e: 0.6114261897943788\n",
      "Epoch: 411 ; loss_e: 0.6038255893577964\n",
      "Epoch: 412 ; loss_e: 0.5926635083505662\n",
      "Epoch: 413 ; loss_e: 0.6126604504504446\n",
      "Epoch: 414 ; loss_e: 0.6108872344938375\n",
      "Epoch: 415 ; loss_e: 0.6095968464673576\n",
      "Epoch: 416 ; loss_e: 0.6016578512676691\n",
      "Epoch: 417 ; loss_e: 0.6115579443462824\n",
      "Epoch: 418 ; loss_e: 0.6158711445533623\n",
      "Epoch: 419 ; loss_e: 0.5972459962812521\n",
      "Epoch: 420 ; loss_e: 0.5981835005647045\n",
      "Epoch: 421 ; loss_e: 0.6167081331802626\n",
      "Epoch: 422 ; loss_e: 0.611082929675862\n",
      "Epoch: 423 ; loss_e: 0.6128240338826584\n",
      "Epoch: 424 ; loss_e: 0.6174701007746034\n",
      "Epoch: 425 ; loss_e: 0.6072931208852994\n",
      "Epoch: 426 ; loss_e: 0.6069875086768198\n",
      "Epoch: 427 ; loss_e: 0.6020311642501314\n",
      "Epoch: 428 ; loss_e: 0.6134389861155365\n",
      "Epoch: 429 ; loss_e: 0.6108215279498342\n",
      "Epoch: 430 ; loss_e: 0.6160341945745177\n",
      "Epoch: 431 ; loss_e: 0.6376779746201079\n",
      "Epoch: 432 ; loss_e: 0.6072697295980939\n",
      "Epoch: 433 ; loss_e: 0.5985941422187676\n",
      "Epoch: 434 ; loss_e: 0.6257001808134176\n",
      "Epoch: 435 ; loss_e: 0.5934483156365863\n",
      "Epoch: 436 ; loss_e: 0.5890181852599322\n",
      "Epoch: 437 ; loss_e: 0.6085445840479964\n",
      "Epoch: 438 ; loss_e: 0.606367947691578\n",
      "Epoch: 439 ; loss_e: 0.6304830555188454\n",
      "Epoch: 440 ; loss_e: 0.6157426753286588\n",
      "Epoch: 441 ; loss_e: 0.5968189279911882\n",
      "Epoch: 442 ; loss_e: 0.6055148334826453\n",
      "Epoch: 443 ; loss_e: 0.6031185368360099\n",
      "Epoch: 444 ; loss_e: 0.6066878508713286\n",
      "Epoch: 445 ; loss_e: 0.603887056900283\n",
      "Epoch: 446 ; loss_e: 0.6042247687355947\n",
      "Epoch: 447 ; loss_e: 0.6075129549382097\n",
      "Epoch: 448 ; loss_e: 0.6054554268465204\n",
      "Epoch: 449 ; loss_e: 0.6116920992479487\n",
      "Epoch: 450 ; loss_e: 0.6077338699567116\n",
      "Epoch: 451 ; loss_e: 0.6056394779076011\n",
      "Epoch: 452 ; loss_e: 0.6062000525199761\n",
      "Epoch: 453 ; loss_e: 0.608883881973008\n",
      "Epoch: 454 ; loss_e: 0.6185015662241791\n",
      "Epoch: 455 ; loss_e: 0.6133624315261841\n",
      "Epoch: 456 ; loss_e: 0.5865526744874857\n",
      "Epoch: 457 ; loss_e: 0.5963586952726719\n",
      "Epoch: 458 ; loss_e: 0.5937149039769577\n",
      "Epoch: 459 ; loss_e: 0.5968432466862565\n",
      "Epoch: 460 ; loss_e: 0.5885669679965003\n",
      "Epoch: 461 ; loss_e: 0.6045093536376953\n",
      "Epoch: 462 ; loss_e: 0.5930586932069164\n",
      "Epoch: 463 ; loss_e: 0.5892989554647672\n",
      "Epoch: 464 ; loss_e: 0.6107226549568823\n",
      "Epoch: 465 ; loss_e: 0.5999227944066969\n",
      "Epoch: 466 ; loss_e: 0.5964294308322972\n",
      "Epoch: 467 ; loss_e: 0.6260851843882416\n",
      "Epoch: 468 ; loss_e: 0.6095128059387207\n",
      "Epoch: 469 ; loss_e: 0.6252193450927734\n",
      "Epoch: 470 ; loss_e: 0.5954257290242082\n",
      "Epoch: 471 ; loss_e: 0.616024225445117\n",
      "Epoch: 472 ; loss_e: 0.5895954734188015\n",
      "Epoch: 473 ; loss_e: 0.6057917930312076\n",
      "Epoch: 474 ; loss_e: 0.6039696830814167\n",
      "Epoch: 475 ; loss_e: 0.5996277797020088\n",
      "Epoch: 476 ; loss_e: 0.6116369356543331\n",
      "Epoch: 477 ; loss_e: 0.595274824207112\n",
      "Epoch: 478 ; loss_e: 0.5977713334358344\n",
      "Epoch: 479 ; loss_e: 0.6020318229319686\n",
      "Epoch: 480 ; loss_e: 0.5904837200197123\n",
      "Epoch: 481 ; loss_e: 0.5939471357959812\n",
      "Epoch: 482 ; loss_e: 0.6008357496584876\n",
      "Epoch: 483 ; loss_e: 0.5881030680769581\n",
      "Epoch: 484 ; loss_e: 0.6125163021734206\n",
      "Epoch: 485 ; loss_e: 0.6038943569538957\n",
      "Epoch: 486 ; loss_e: 0.5841608512199531\n",
      "Epoch: 487 ; loss_e: 0.5984576597052106\n",
      "Epoch: 488 ; loss_e: 0.594472913418786\n",
      "Epoch: 489 ; loss_e: 0.5998568959155325\n",
      "Epoch: 490 ; loss_e: 0.6035060640108787\n",
      "Epoch: 491 ; loss_e: 0.596122266882557\n",
      "Epoch: 492 ; loss_e: 0.5998711363743927\n",
      "Epoch: 493 ; loss_e: 0.6115442676059271\n",
      "Epoch: 494 ; loss_e: 0.5940895060361442\n",
      "Epoch: 495 ; loss_e: 0.603575918634059\n",
      "Epoch: 496 ; loss_e: 0.602444915448205\n",
      "Epoch: 497 ; loss_e: 0.5982837474952309\n",
      "Epoch: 498 ; loss_e: 0.6089231887106168\n",
      "Epoch: 499 ; loss_e: 0.6286965204497516\n",
      "Epoch: 500 ; loss_e: 0.5912744938316992\n",
      "Epoch: 501 ; loss_e: 0.6075521929789398\n",
      "Epoch: 502 ; loss_e: 0.5836102982698861\n",
      "Epoch: 503 ; loss_e: 0.5827166912919384\n",
      "Epoch: 504 ; loss_e: 0.5958116034329948\n",
      "Epoch: 505 ; loss_e: 0.5948836641796564\n",
      "Epoch: 506 ; loss_e: 0.5788565227540873\n",
      "Epoch: 507 ; loss_e: 0.5908429784289861\n",
      "Epoch: 508 ; loss_e: 0.592192801378541\n",
      "Epoch: 509 ; loss_e: 0.5935987395755316\n",
      "Epoch: 510 ; loss_e: 0.5923254085799395\n",
      "Epoch: 511 ; loss_e: 0.5910066548040358\n",
      "Epoch: 512 ; loss_e: 0.5916829796160682\n",
      "Epoch: 513 ; loss_e: 0.5786681458101435\n",
      "Epoch: 514 ; loss_e: 0.5846677594265696\n",
      "Epoch: 515 ; loss_e: 0.5933345475439298\n",
      "Epoch: 516 ; loss_e: 0.6083726983959392\n",
      "Epoch: 517 ; loss_e: 0.5983808323488398\n",
      "Epoch: 518 ; loss_e: 0.5999409970590623\n",
      "Epoch: 519 ; loss_e: 0.5932875063459752\n",
      "Epoch: 520 ; loss_e: 0.5930152666770806\n",
      "Epoch: 521 ; loss_e: 0.5938777741739305\n",
      "Epoch: 522 ; loss_e: 0.595783162925203\n",
      "Epoch: 523 ; loss_e: 0.5950740979889692\n",
      "Epoch: 524 ; loss_e: 0.5987329422417333\n",
      "Epoch: 525 ; loss_e: 0.5941270084704383\n",
      "Epoch: 526 ; loss_e: 0.6225133063429493\n",
      "Epoch: 527 ; loss_e: 0.5825573125128019\n",
      "Epoch: 528 ; loss_e: 0.5800053689439418\n",
      "Epoch: 529 ; loss_e: 0.5963673207719448\n",
      "Epoch: 530 ; loss_e: 0.585828362885168\n",
      "Epoch: 531 ; loss_e: 0.5752397876674846\n",
      "Epoch: 532 ; loss_e: 0.5835603354340893\n",
      "Epoch: 533 ; loss_e: 0.5796806489006948\n",
      "Epoch: 534 ; loss_e: 0.6308129399509753\n",
      "Epoch: 535 ; loss_e: 0.5792446156679574\n",
      "Epoch: 536 ; loss_e: 0.5869661205905979\n",
      "Epoch: 537 ; loss_e: 0.588398935431141\n",
      "Epoch: 538 ; loss_e: 0.6111645051988505\n",
      "Epoch: 539 ; loss_e: 0.5998579970860886\n",
      "Epoch: 540 ; loss_e: 0.5948949183447886\n",
      "Epoch: 541 ; loss_e: 0.6093313774820102\n",
      "Epoch: 542 ; loss_e: 0.5900410050052708\n",
      "Epoch: 543 ; loss_e: 0.6032355599484202\n",
      "Epoch: 544 ; loss_e: 0.5754655781438796\n",
      "Epoch: 545 ; loss_e: 0.5870406971139422\n",
      "Epoch: 546 ; loss_e: 0.5808466167773231\n",
      "Epoch: 547 ; loss_e: 0.5757899021698256\n",
      "Epoch: 548 ; loss_e: 0.6012201127359422\n",
      "Epoch: 549 ; loss_e: 0.5908143803224726\n",
      "Epoch: 550 ; loss_e: 0.6112170077986636\n",
      "Epoch: 551 ; loss_e: 0.5962547488131765\n",
      "Epoch: 552 ; loss_e: 0.5998640585753877\n",
      "Epoch: 553 ; loss_e: 0.5989007889214208\n",
      "Epoch: 554 ; loss_e: 0.5815412412255497\n",
      "Epoch: 555 ; loss_e: 0.5980406716718512\n",
      "Epoch: 556 ; loss_e: 0.5901744527331854\n",
      "Epoch: 557 ; loss_e: 0.5944101325536179\n",
      "Epoch: 558 ; loss_e: 0.5726699829101562\n",
      "Epoch: 559 ; loss_e: 0.5871849241903273\n",
      "Epoch: 560 ; loss_e: 0.6009381140692759\n",
      "Epoch: 561 ; loss_e: 0.5843568818043854\n",
      "Epoch: 562 ; loss_e: 0.593492716045703\n",
      "Epoch: 563 ; loss_e: 0.5884284144740993\n",
      "Epoch: 564 ; loss_e: 0.5936414932800551\n",
      "Epoch: 565 ; loss_e: 0.5716465004419876\n",
      "Epoch: 566 ; loss_e: 0.5825647297552077\n",
      "Epoch: 567 ; loss_e: 0.5830047170994646\n",
      "Epoch: 568 ; loss_e: 0.5742752834901972\n",
      "Epoch: 569 ; loss_e: 0.5975519782405788\n",
      "Epoch: 570 ; loss_e: 0.5833592980594958\n",
      "Epoch: 571 ; loss_e: 0.5960863444764736\n",
      "Epoch: 572 ; loss_e: 0.5913628844891564\n",
      "Epoch: 573 ; loss_e: 0.6009553973957643\n",
      "Epoch: 574 ; loss_e: 0.5848985183036933\n",
      "Epoch: 575 ; loss_e: 0.582378565254858\n"
     ]
    }
   ],
   "source": [
    "##########################################################\n",
    "# Train the model\n",
    "##########################################################\n",
    "training = Trainer(model=model, warmup_iteration=args.warmup_iteration, seq_length=seq_length,\n",
    "                   batch_size=args.batch_size, num_workers=args.num_workers, vocab_size=vocab_size,\n",
    "                   model_dir = args.model_dir, save_iter=args.save_iter)\n",
    "print('begin training...')\n",
    "training.train(args.num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85de3e04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "progen-salesforce",
   "language": "python",
   "name": "progen-salesforce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
